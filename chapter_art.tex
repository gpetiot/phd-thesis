
\chapter[État de l'art]{Combinaisons d'analyses statiques et dynamiques pour
  l'aide à la preuve}
\label{sec:state-art}


\chapterintro


Dans ce chapitre nous passons en revue les travaux existants combinant analyses
statiques et analyses dynamiques, et en particulier ceux qui ont pour objectif
d'aider la vérification déductive.
Nous présentons leurs forces et leurs faiblesses puis concluons en mettant en
avant la contribution que nous souhaitons apporter à ces domaines.
La partie~\ref{sec:art-comb} présente les travaux combinant analyses statiques
et dynamiques et la partie~\ref{sec:art-proof} recense les travaux visant à
aider la vérification déductive de programmes.


\section{Combinaisons d'analyses statiques et dynamiques}
\label{sec:art-comb}


Les méthodes statiques et les méthodes dynamiques ont des avantages et des
inconvénients complémentaires : l'analyse statique est complète mais
imprécise, l'analyse dynamique est précise mais incomplète.
L’idée de les combiner pour associer leurs avantages et combattre leurs
inconvénients \cite{Ernst/WODA03} est une voie de recherche active et fructueuse
dans le domaine de la vérification de programmes.


\subsubsection*{Vérification formelle et test avec \spark}


L'intégration de la vérification formelle dans un processus de validation à base
de tests (comme c'est le cas dans l'avionique) est présenté dans
\cite{Comar/ERTS12} dans le cadre de la plate-forme \spark.
\spark~\cite{\citespark} est un sous-ensemble du langage Ada orienté pour la
conception d'applications critiques sûres et sécurisées.
C'est aussi un écosystème d'outils contenant entre autres l'outil de preuve
\textsc{SPARKprove} et l'outil de test \textsc{SPARKtest}.
\cite{Comar/ERTS12} présente la vérification des contrats \spark implicites et
des contrats définis par l'utilisateur, ainsi que la définition de cas de tests
formels dans les contrats \spark.
La vérification des hypothèses utilisées par la preuve ou le test d'une partie
d'un programme \spark est présentée dans \cite{Kanig/TAP14}.
La méthodologie utilisée permet uniquement d'utiliser le test ou la preuve sur
une fonction, contrairement à \framac où il est possible d'utiliser différentes
techniques de vérification (interprétation abstraite, calcul de plus faible
précondition, etc.) sur différentes propriétés d'une même fonction.


\subsubsection*{Détection des erreurs à l'exécution dans \sante}


La méthode \sante (\textsc{Static ANalysis and TEst})
\cite{Chebaro/11, \citesante} pour la détection des erreurs à l'exécution, mise
en \oe{}uvre au sein de \framac, combine l'interprétation abstraite, le
{\em slicing} et la génération de tests structurels avec \pathcrawler.

L'analyse de valeurs (par interprétation abstraite) sélectionne les instructions
pour lesquelles le risque d'une erreur à
l'exécution n'est pas écarté (nous les appellerons ``alarmes'' par la suite),
par exemple une division par zéro ou un accès invalide à la mémoire.
Ces alarmes vont être confirmées ou non par des tests.
L'outil de génération de tests structurels \pathcrawler \cite{\citepathcrawler}
est utilisé pour tenter de mettre en évidence un cas de test pour lequel le
chemin d'exécution passe par cette alarme et provoque une erreur.

Pour diminuer le coût de la génération de tests, \sante simplifie syntaxiquement
les programmes qui lui seront soumis pour ne garder que les instructions dont
dépend l'alarme considérée, on appelle cette opération le {\em slicing}.
Des programmes plus simples sont ainsi obtenus, tels que si on constate une
erreur dans un programme simplifié, alors cette erreur existe dans le programme
d'origine.

La première phase de la méthode (l'interprétation abstraite) peut donc assurer
que certaines instructions ne provoqueront pas d'erreur à l'exécution, tandis
que la seconde phase permet de confirmer que certaines alarmes produisent
effectivement une erreur à l'exécution.
La mise en commun des résultats des deux phases permet de classifier plus
d'alarmes que chacune des deux méthodes prise séparément.


\subsubsection*{Détection d'erreurs guidée par analyse statique avec \dyta}


\dyta \cite{\citedyta} est un outil combinant une phase d'analyse statique et
une phase d'analyse dynamique. \codecontracts \cite{\citecodecontracts} est
utilisé pour spécifier des pré/post-conditions et des invariants de programmes
C\#, il identifie également les bugs potentiels (violations de contrat) par
interprétation abstraite.
La deuxième étape utilise la génération de tests par exécution symbolique
dynamique avec \pex~\cite{\citepex}.

\dyta instrumente le programme pour ajouter des instructions assurant le rôle de
pré-conditions, pour ne pas générer de cas de test qui n'ont aucune chance de
produire d'erreur à l'exécution.
L'instrumentation ajoute également des points de contrôle à l'endroit des
instructions signalées par l'analyse statique, afin de guider l'exécution
symbolique dynamique du programme par \pex.
Cette étape est semblable à l'instrumentation opérée par \sante pour rajouter
des points de contrôle afin de guider l'exécution concolique du programme par
\pathcrawler.

L'analyse statique du graphe du flot de contrôle du programme permet à
\dyta de calculer les points de contrôle à partir desquels les instructions
potentiellement dangereuses sont inatteignables.
La génération de tests réduit le nombre de faux positifs de l'analyse statique,
et cette dernière guide l'exploration pour la génération de tests.


\subsubsection*{Vérification collaborative et test}


La méthode de \cite{Christakis/FM12} part du constat que la plupart
des outils de vérification statique (outils utilisant simplement des
heuristiques, outils d'interprétation abstraite, model-checkers, ou outils de
preuve) font des compromis afin d'améliorer les performances, de réduire le
nombre de faux positifs ou de limiter l'effort à fournir pour annoter le
programme. Cela se traduit par la supposition d'une propriété tout au long de
l'analyse du programme (par exemple qu'un certain type d'erreurs ne peuvent pas
se produire).
Cette propriété n'est pas vérifiée par l'analyseur.
Ceci implique que de tels analyseurs ne peuvent garantir l'absence d'erreurs
dans un programme.
Si un analyseur fait un compromis en supposant une propriété, il faut utiliser
un autre analyseur capable de valider cette propriété.

Cette méthode propose d'exprimer les compromis dans un langage de contrats,
afin de faciliter la collaboration entre plusieurs outils d'analyse statique
et permettant de décrire le fait qu'une assertion a été complètement vérifiée
par un analyseur ou partiellement vérifiée sous certaines hypothèses.

Pour faciliter la vérification statique du programme, l'utilisateur doit au
préalable ajouter des annotations (invariants de boucle par exemple). Les
propriétés qui n'ont pas été vérifiées statiquement sont validées par des tests
unitaires. Le programme est instrumenté afin d'ajouter des vérifications à
l'exécution pour guider la génération de contre-exemples.
\pex~\cite{\citepex} est utilisé pour générer des cas de test par exécution
concolique, mettant en évidence des contre-exemples.
L'utilisateur peut décider de privilégier l'analyse statique ou le test selon
qu'il spécifie ou non son programme.


\subsubsection*{Vérification de propriétés décrites par des automates finis}


La méthode de \cite{Slaby/FMICS12} combine une instrumentation du
code source, une étape de {\em slicing} et une exécution symbolique.
L'instrumentation ajoute des instructions simulant le comportement de
l'automate fini correspondant au programme, dont les états correspondent aux
propriétés du programme à vérifier.
Le {\em slicing} est appliqué pour réduire la taille du programme afin de ne
conserver que le code relatif aux états d'erreur de l'automate. Le programme
simplifié doit être équivalent au programme instrumenté en ce qui concerne
l'atteignabilité des états d'erreur de l'automate.
L'exécution symbolique du programme par \klee \cite{\citeklee} permet
de mettre en évidence des contre-exemples pour ces propriétés.


\subsubsection*{Localisation d'erreurs par slicing guidé par une trace
  d'exécution}


La méthode de \cite{Jiang/QSIC12} utilise un {\em slicing} arrière à
partir d'une instruction de déréférencement produisant une {\em Null Pointer
Exception} (en Java). Le {\em slicing} est guidé par une trace du programme
fournissant la pile des appels de méthodes n'ayant pas terminé. Une analyse
statique des pointeurs est ensuite opérée sur le programme slicé afin de
déterminer si chacun des pointeurs peut être \lstinline[language=java]{null}.
Puis une analyse d'alias est opérée afin d'augmenter la précision de l'analyse
statique.


\subsubsection*{\cegar : Raffinement d'abstraction guidé par des
  contre-exemples}


Le raffinement d'abstraction guidé par des contre-exemples
\cite{\citecegar, Pasareanu/07} associe l’abstraction par prédicats
\cite{Ball/FMCO04} et le model-checking : une abstraction du programme
est générée à partir d’un ensemble de prédicats et invariants. Si le
model-checking prouve la non-accessibilité des états d'erreurs de l'automate,
alors le modèle concret est correct.
Si le model-checking a trouvé un contre-exemple pour le modèle abstrait il faut
déterminer s'il correspond à un contre-exemple réel dans le système concret.
Pour cela, l'algorithme détermine s'il existe une trace d'exécution concrète
correspondant à la trace d'exécution abstraite aboutissant au contre-exemple.
Si une telle trace existe, un bug a été trouvé. Sinon, de nouveaux prédicats
sont créés pour raffiner l'abstraction afin que ce contre-exemple en soit
absent à la prochaine itération. Et ainsi de suite. Ce processus peut ne pas
terminer. Plusieurs outils de vérification se basent sur cette méthode, parmi
lesquels \blast \cite{\citeblast}, \magic \cite{\citemagic} et
\slam \cite{\citeslam}.

Cette approche élimine les contre-exemples un par un, et peut donc ne pas
converger.
Une amélioration a été proposée afin d'accélérer la convergence du
raffinement de l'abstraction : \cegaar \cite{\citecegaar}. Cette technique
élimine une infinité de contre-exemples (traces infaisables) de la forme
$\alpha . \lambda^{*} . \beta$ en une seule étape, où $\lambda$ correspond à un
nombre quelconque d'exécutions d'une boucle.


\subsubsection*{Vérification des propriétés temporelles de sûreté avec \blast}


\blast \cite{\citeblast} vérifie les propriétés temporelles de sûreté d'un
programme C, ou met en évidence un chemin d'exécution violant une propriété.
Le raffinement des abstractions du programme est basé sur une abstraction par
prédicats et la découverte des prédicats se fait par interpolation.
C'est une implémentation de la méthode \cegar \cite{\citecegar} tout comme
\slam \cite{\citeslam} et \magic \cite{\citemagic}.
La génération des cas de test se fait par exécution symbolique.

\blast ne traite ni les débordements arithmétiques ni les opérations
bit-à-bit, et considère que toutes les opérations arithmétiques sur les
pointeurs sont sûres.
Le langage d'invariants utilisé pour décrire les propriétés ne contient pas de
quantificateurs.


\subsubsection*{Génération de tests avec résumés : \smart}


\smart ({\em Systematic Modular Automated Random Testing}) \cite{\citesmart},
basé sur son prédécesseur \dart ({\em Directed Automated Random Testing})
\cite{\citedart} génère des tests par exécution concolique.
Pour résoudre le problème de l'explosion du nombre de chemins, il va calculer à
la demande des résumés de fonction qui sont des contrats (pré-conditions et
post-conditions) pour chaque fonction (contraintes sur les variables en entrée
et en sortie).
Ces résumés vont être réutilisés si possible afin d'éviter de ré-exécuter la
fonction correspondante.
La génération automatique de ces résumés se base sur une exécution symbolique et
une résolution de contraintes.
\smart exécute une analyse dynamique compositionnelle, c'est-à-dire que les
résultats intermédiaires sont mémorisés sous la forme de résumés réutilisables.
C'est une extension de l'algorithme d'analyse dynamique non compositionnelle de
\dart.


\subsubsection*{Collaboration de sur-approximation et sous-approximation}


\synergy~\cite{\citesynergy} est un algorithme combinant du test (essayer
d'atteindre un état d'erreur) et une abstraction (trouver une abstraction
suffisamment précise montrant qu'aucun chemin ne peut atteindre un état
d'erreur).
La sous-approximation du test et la sur-approximation de l'abstraction sont
raffinées de manière itérative.
L'abstraction est utilisée pour guider la génération de tests.
Les tests sont utilisés pour décider {\em où} raffiner l'abstraction.
Les états de l'abstraction, les régions, sont des classes d'équivalence des
états du programme concret.
S'il n'existe aucun chemin de la région initiale vers une région d'erreur, alors
il n'existe aucune suite de transitions concrètes menant d'un état initial
concret à un état d'erreur concret.
\synergy combine \slam et \dart (\cegar compositionnel et test non
compositionnel).
L'algorithme est intra-procédural.

\dash~\cite{\citedash} est une évolution de \synergy, prenant en compte les
appels de procédure et les pointeurs (contrairement à \synergy).
\dash est inter-procédural mais non compositionnel.
\dash raffine l'abstraction en utilisant uniquement les relations d'alias mises
en évidence par les tests.
La génération de tests détermine non seulement {\em où} raffiner l'abstraction,
mais aussi {\em comment} la raffiner.
Cet algorithme est implémenté dans \yogi~\cite{\citeyogi}.

\Smash est la version compositionnelle de \dash~\cite{\citedash}.
\Smash~\cite{\citesmash} combine une abstraction par prédicats et une génération
dynamique de tests (par exécution concolique).
Pour chaque fonction, un résumé est calculé par analyse statique (vrai pour
toutes les exécutions, permettant de prouver l'absence d'erreurs, c'est une
sur-approximation) et un autre résumé est calculé par analyse dynamique (vrai
pour quelques exécutions uniquement, permettant de montrer l'existence
d'erreurs, c'est une sous-approximation).
Ces résumés sont calculés à la demande et seront utilisés aussi bien par
l'analyse statique que par l'analyse dynamique (les deux analyses s'exécutent
simultanément).
Ces résumés sont progressivement raffinés pour chaque fonction, afin de prouver
qu'une propriété n'est jamais violée (si un résumé statique est applicable), ou
de mettre en évidence une exécution violant une propriété (si un résumé
dynamique est applicable).
Par construction, il n'est pas possible que les deux résumés soient applicables.


\subsubsection*{Analyses statique et dynamique pour la génération d'invariants}


\cite{Gupta/TACAS09} propose une solution au problème du
passage à l'échelle de la génération d'invariants (de programmes impératifs) par
résolution de contraintes. Les invariants arithmétiques linéaires sont générés
d'après les informations obtenues par interprétation abstraite du programme, par
exécution concrète et par exécution symbolique du programme. Ces informations
permettent de générer des contraintes qui vont permettre au solveur de
contraintes de simplifier le système de contraintes et de réduire l'espace de
recherche.


\subsubsection*{Recherche d'erreurs par détection d'invariants avec \dsdcrasher
  et \checkncrash}


L'outil \dsdcrasher \cite{\citedsdcrasher} combine une première analyse
dynamique, une analyse statique et une seconde analyse dynamique.
La première analyse dynamique utilise une génération de tests et des techniques
d'apprentissage pour générer des invariants probables (inférence de la
spécification par \daikon \cite{\citedaikon}).

Les deux dernières étapes sont celles de l'outil \checkncrash
\cite{\citecheckncrash}.
L'analyse statique (\escjavatwo \cite{\citeescjavatwo}) va émettre des alarmes
concernant le non-respect des invariants, et la seconde analyse dynamique va
tenter de confirmer ces alarmes par résolution de contraintes et génération de
tests (\jcrasher \cite{\citejcrasher}).
La classification des alarmes et la génération de tests sont très dépendantes de
la qualité des invariants générés par \daikon.


\subsubsection*{Génération de données de test par algorithme génétique}


\cite{Romano/ICST11} propose une méthode de génération de données
de test mettant en évidence des {\em Null Pointer Exceptions} de Java. Tout
d'abord une analyse inter-procédurale du flot de contrôle et du flot de données
collecte les chemins menant aux exceptions. Cette analyse se fait en arrière, en
partant des exceptions, propageant les contraintes sur les entrées dans le
graphe de flot de contrôle.
Les entrées de test sont ensuite générées par un algorithme génétique, dans le
but de couvrir ces chemins. Les individus (des entrées potentielles), dont le
type de donnée peut être complexe, sont encodés sous forme XML.

Cette méthode a été comparée avec d'autres façons de générer des données de
test \cite{Ahn/TAP10}.
Les expérimentations présentées dans \cite{Romano/ICST11} ont montré que la
méthode était plus efficace que d'autres stratégies de recherche optimale comme
le {\em hill climbing} et le recuit simulé, mais est moins efficace que la
programmation par contraintes (en terme de temps d'exécution).


\subsubsection*{Preuve et validation à l'exécution}


La plateforme \textsc{staRVOOrS} ({\em Static and Runtime Verification
  of Object-Oriented Software}) \cite{Ahrendt/FM15} propose une vérification en
deux étapes : vérification déductive du programme avec \textsc{KeY} afin de
prouver les propriétés portant sur les données, puis une validation à
l'exécution avec \textsc{Larva} ({\em Logical Automata for Runtime Verification
  and Analysis}) afin de vérifier les propriétés portant sur le
flot de contrôle.
Cette méthode repose sur \textsc{ppDATE}, un langage de spécification encodant
les propriétés du flot de contrôle par des automates, où les états de
l'automate sont augmentés par des pré- et postconditions (à la \jml) afin
d'encoder les propriétés fonctionnelles du programme.


\section{Aide à la preuve de programmes}
\label{sec:art-proof}


\subsubsection*{Analyse des arbres de preuve}


Un diagnostic plus précis en cas d'échec de preuve peut être obtenu en analysant
statiquement les branches d'un arbre de preuve.
La méthode proposée par \cite{Gladisch/TAP09} dans le contexte du prouveur
\textsc{KeY} applique des règles de déduction à une formule mêlant le programme
et sa spécification.
Cette méthode propose une vérification de la préservation de falsifiabilité
({\em falsifiability preservation checking}) qui permet de décider si l'échec
de preuve d'une branche provient d'une erreur ou d'une faiblesse de contrat.
Cependant, cette technique ne peut détecter les erreurs que si les contrats sont
suffisamment forts et elle n'est automatique que si le prouveur peut décider la
(non-)satisfaisabilité d'une formule logique de premier ordre exprimant la
condition de la préservation de falsifiabilité.

\cite{Engel/TAP07} présente une méthode de génération automatique de tests
unitaires pour \textsc{Java Card} à partir d'une tentative de preuve par le
prouveur \textsc{KeY}.
Ici aussi, les arbres de preuve générés par \textsc{KeY} sont exploités.
L'information contenue dans la preuve (même partielle) est utilisée
pour extraire des données de test à partir des conditions de chemins et les
oracles sont générés à partir des postconditions.
En revanche, la pertinence des tests générés dépend de la qualité de la
spécification écrite par l'utilisateur, et ne permet pas de distinguer les
échecs de preuve dus à une non-conformité des échecs de preuve dus à une
faiblesse de spécification.


\subsubsection*{Compréhension des échecs}


\cite{Tschannen/14} propose une vérification en deux étapes qui compare les
échecs de preuve d'un programme \eiffel avec et sans déroulage des boucles et
{\em inlining} des fonctions.
Cette méthode suggère des modifications à apporter au code et à la spécification
après comparaison des échecs de preuve.
L'{\em inlining} des fonctions et le déroulage des boucles sont limités
respectivement à un nombre donné d'appels imbriqués et à un nombre donné
d'itérations.
Si ce nombre est insuffisant, la sémantique du programme initial est perdue et
la fiabilité des résultats en est affectée.

\cite{Claessen/TAP08} propose une méthode de génération de contre-exemples
montrant que les invariants inductifs d'un système de transitions sont trop
forts ou trop faibles.
Leur méthode utilise le test aléatoire (avec \textsc{QuickCheck}) et cible
la vérification des systèmes de transitions et des protocoles, ce qui
la rend difficilement applicable à la vérification de programmes.


\subsubsection*{Vérification des hypothèses}


Les axiomes sont des propriétés logiques utilisées comme hypothèses par les
prouveurs et sont donc rarement vérifiés.
Néanmoins, les vérifier permet de s'assurer de la cohérence d'une
axiomatisation.
\cite{Ahn/TAP10} propose d'appliquer du test à base de modèles
({\em model-based testing}) sur un modèle défini à partir d'un axiome afin de
détecter les erreurs éventuelles dans les axiomes.
Ce travail s'intéresse au cas où la vérification déductive réussit à cause
d'une axiomatisation invalide (incohérence), ce qui est complémentaire à nos
motivations qui visent à traiter le cas où la vérification déductive échoue.

\cite{Christakis/FM12} propose de compléter les résultats des analyses statiques
avec une exécution symbolique dynamique utilisant \pex.
Les hypothèses explicites utilisées par la preuve (absence de
débordement arithmétique, absence d'{\em aliasing}, etc.) créent de nouvelles
branches dans le graphe de flot de contrôle du programme, que \pex essaiera
ensuite d'explorer.
Cette approche permet de détecter des erreurs hors de portée des analyseurs
statiques considérés, mais ne génère pas de contre-exemples en cas de
spécification trop faible.


\subsubsection*{Exécution des contre-exemples}


\cite{Muller/FM11} propose d'étendre un vérificateur d'assertions à l'exécution
({\em runtime assertion checker}) afin de l'utiliser comme débogueur
({\em debugger}) pour comprendre les contre-exemples d'échecs de preuve
complexes.

L'environnement de développement \dafny \cite{\citedafny} fournit un retour à
l'utilisateur pendant la phase de développement.
\dafny intègre le \boogie {\em Verification Debugger} \cite{LeGoues/SEFM11}
qui aide l'utilisateur à comprendre les contre-exemples produits par des
outils de vérification tels que \boogie.
Actuellement, \dafny ne supporte que les contre-exemples fournis par le solveur
et ne produit pas d'informations supplémentaires quand la vérification échoue
ou atteint un {\em timeout}.


\section*{Conclusion du chapitre}


Nous avons présenté dans ce chapitre les différents travaux de vérification
existants qui combinent analyses statiques et analyses dynamiques ou qui visent
à aider la vérification déductive.
Parmi eux, nous poursuivons des travaux précédents~\cite{Chebaro/SAC12} afin
d'aider la vérification déductive par la génération de contre-exemples par
exécution concolique.
Nous présentons dans les chapitres suivants une technique originale de
diagnostic des échecs de preuve.
En particulier, la thèse que nous défendons est que les contre-exemples générés
par notre méthode par analyse dynamique permettent de mieux identifier la raison
des échecs de preuve qu'un contre-exemple extrait à partir d'un prouveur.
Nous affirmons par la même occasion l'indépendance de notre méthode vis-à-vis
des prouveurs sous-jacents utilisés.
À notre connaissance, une telle méthode combinant le test et la preuve,
fournissant automatiquement un retour aussi précis à l'utilisateur quant à la
raison des échecs de preuve, n'a pas été étudiée, implémentée et expérimentée
auparavant.

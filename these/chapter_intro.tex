
\chapter{Introduction}
\label{sec:intro}


\chapterintro


Cette thèse se place dans le contexte de la vérification et de la validation des
logiciels.
Les principales approches de ce domaine sont présentées en partie~\ref{sec:vv}.
Nous y présentons notamment les outils que nous utilisons dans nos travaux :
\pathcrawler en partie~\ref{sec:test-structurel} et \framac en
partie~\ref{sec:framac}.
Nous expliquons la problématique de nos travaux et nos motivations en
partie~\ref{sec:pb-motiv}.
Les contributions de cette thèse sont présentées en partie~\ref{sec:contrib} et
le plan de la thèse est annoncé en partie~\ref{sec:plan}.


\section{Vérification et validation de programmes}
\label{sec:vv}


Le domaine de la vérification et de la validation regroupe un ensemble de
techniques du cycle de développement des logiciels qui ont pour objectif de
s'assurer de leur bon fonctionnement (notamment de leur correction et de leur
sûreté).
Ces deux notions sont apparues dans les années soixante-dix avec les travaux de
\bsc{Dijkstra}~\cite{Dijkstra/75}, \bsc{Floyd}~\cite{Floyd/63} et
\bsc{Hoare}~\cite{Hoare/69}.

\cite{PMBOK} définit la \emph{validation} comme l'assurance qu'un produit,
service ou système répond au besoin des utilisateurs extérieurs.
La \emph{vérification} est l'évaluation d'un produit, service ou système afin de
déterminer s'il est conforme à des règles, des spécifications ou des
contraintes.
Contrairement à la validation, la vérification est le plus souvent un processus
interne.

Nous présentons d'abord en partie~\ref{sec:model-checking} une technique de
vérification appelée {\em model-checking} applicable aux systèmes à nombre fini
d'états et qui consiste à examiner toutes les exécutions du système.
En partie~\ref{sec:AS} nous présentons des méthodes de vérification par
analyse statique du code, c'est-à-dire ne nécessitant pas d'exécuter le
programme.
En partie~\ref{sec:AD} nous présentons des méthodes de validation par analyse
dynamique du code, c'est-à-dire nécessitant d'exécuter le programme.
Celles-ci permettent d'effectuer la vérification du programme dans le cas
particulier où le nombre d'exécutions est fini et suffisamment petit.
%% La vérification d'un programme consiste à s'assurer de la conformité de son code
%% vis-à-vis de sa spécification, c'est-à-dire de la correction d'un programme.
%% Elle s'appuie sur des méthodes d'analyse statique, c'est-à-dire ne nécessitant
%% pas d'exécuter le programme, présentées en partie~\ref{sec:AS}.
%% La validation d'un programme consiste à s'assurer de la conformité de
%% l'exécution du programme aux attentes de l'utilisateur.
%% Elle s'appuie sur des méthodes d'analyse dynamique qui nécessitent d'exécuter
%% le programme, présentées en partie~\ref{sec:AD}.
En partie~\ref{sec:speclang} nous présentons les langages de spécification, qui
permettent d'encoder de manière formelle les propriétés du programme à vérifier.
Enfin, nous présentons en partie~\ref{sec:framac} la plateforme de vérification
\framac qui sert de base à nos travaux.


\subsection{Model-checking}
\label{sec:model-checking}


Le model-checking \cite{Queille/82,Clarke/86,Henzinger/94,Clarke/09} permet de
vérifier algorithmiquement si un modèle donné (le système ou une abstraction de
ce système) satisfait une spécification, formulée en logique temporelle
\cite{Clarke/82}.
Un modèle est un ensemble d'états, de propriétés que vérifie chaque état, et de
transitions entre ces états qui décrivent l'évolution du système.

Le model-checking couvre l'ensemble des états et des transitions du système afin
d'analyser toutes les exécutions possibles du système. Sur de grands systèmes,
cette méthode est pénalisée par l'explosion combinatoire du nombre des états (et
la complexité en temps ou en espace qui en résulte). Il est néanmoins possible
de modéliser des algorithmes asynchrones répartis et des automates non
déterministes, comme le permet notamment l'outil \spin~\cite{\citespin}.

%% La plateforme \framac intègre \textsc{Aoraï}, un greffon
%% permettant d'annoter automatiquement le code source d'un programme C d'après
%% une formule de logique temporelle linéaire, de sorte que les annotations sont
%% vérifiées si le programme repecte la formule.


\subsection{Analyse statique}
\label{sec:AS}


L'analyse statique \cite{Nielson/99} examine le code source du programme
sans l'exécuter. Elle raisonne sur tous les comportements qui pourraient
survenir lors de l'exécution et permet donc de déduire des propriétés logiques
devant être vérifiées pour toutes ces exécutions, dans le but de prouver la
correction du programme.

En revanche, la vérification de programme étant en général indécidable
\cite{Landi/92}, il est souvent nécessaire d'utiliser des
sur-approximations, ce qui implique que les résultats peuvent être moins précis
que ce que l'on souhaite mais qu'ils sont garantis pour toutes les exécutions.
Ainsi, on peut établir des propriétés de sûreté ({\em safety}), où l’on cherche
des invariants sur les valeurs des variables du programme (une plage de valeurs
par exemple), afin d'exclure certains risques d'erreurs à l'exécution.

Nous présentons les principes de l'analyse statique par interprétation abstraite
en partie~\ref{sec:interpretation-abstraite}.
Nous présentons en partie~\ref{sec:abstraction-predicats} les principes de
l'abstraction à base de prédicats permettant d'obtenir une abstraction du
système à vérifier.
Puis nous présentons l'analyse statique par preuve (ou vérification déductive)
en partie~\ref{sec:preuve}.


\subsubsection{Interprétation abstraite}
\label{sec:interpretation-abstraite}


L'interprétation abstraite \cite{Cousot/92} s'appuie sur les
théories du point fixe et des domaines pour introduire des sur-approximations
des comportements d'un programme.
Elle consiste à abstraire les domaines des variables par d'autres domaines qui
peuvent éventuellement être plus simples.
Par exemple, le domaine des entiers pourrait être abstrait par un domaine de
trois valeurs $(-, 0, +)$ symbolisant respectivement les entiers négatifs,
l'entier nul et les entiers positifs.
Une analyse de valeurs par interprétation abstraite consiste à calculer à chaque
ligne du code une sur-approximation de l’ensemble des valeurs prises par chaque
variable en cette ligne lors de toutes les exécutions du programme, permettant
ainsi de détecter certaines erreurs comme les divisions par zéro ou les accès en
dehors des bornes des tableaux.

Pour contourner le problème d’indécidabilité, la théorie de l’interprétation
abstraite construit une méthode qui, à la même question, répondra ``oui'',
``non'' ou ``peut-être''. Si la méthode répond ``peut-être'', c’est qu’on n’a pu
prouver ni l’un ni l’autre des deux premiers cas. C’est ce qu’on appelle une
alarme : il est possible qu’une des exécutions du programme produise une erreur
donnée, mais la méthode n'est capable ni de le confirmer ni de l’infirmer.
L’erreur signalée par une alarme peut ne jamais apparaître à l’exécution, dans
ce cas on l’appelle fausse alarme. On ne calcule donc pas la propriété exacte
mais une approximation de cette propriété, en imposant la contrainte de sûreté
suivante : ``la propriété abstraite calculée ne doit oublier aucune exécution
concrète''. L'abstraction est effectuée à base de prédicats atomiques
définissant des abstractions des domaines des variables.

\polyspace~\cite{\citepolyspace} utilise l'interprétation abstraite pour
détecter les erreurs à l'exécution dans les programmes en C, C++ et Ada mais
signale beaucoup de fausses alarmes.
L'ENS a développé \astree~\cite{\citeastree}, spécifique au langage C et aux
logiciels critiques.
\fluctuat~\cite{\citefluctuat} mesure précisément les approximations faites à
l'exécution d'un programme C.
\framac intègre un greffon d'interprétation abstraite nommé
\Value~\cite{\citevalue,\citeframac}.


\subsubsection{Abstraction à base de prédicats}
\label{sec:abstraction-predicats}


L'abstraction à base de prédicats \cite{Schiller/OOPSLA12,Ball/FMCO04} est une
technique permettant de générer automatiquement des abstractions ayant un nombre
d'états fini.
Pour un programme $P$ au nombre d'états infini, un ensemble fini de prédicats
$E = \{f_1, ..., f_n\}$ est défini.
Ces prédicats sont des expressions booléennes sur les variables de $P$ et les
constantes du langage.

Chaque état concret de $P$ est mis en correspondance avec un état abstrait de
l'abstraction de $P$, après évaluation par les prédicats de $E$. Un état
abstrait est un $n$-uplet de valeurs booléennes des $n$ prédicats.
Par exemple, si 3 prédicats $f_1, f_2, f_3$ sont définis et si la valeur de ces
prédicats à l'état concret $e$ est évaluée respectivement à $false, true, true$,
alors l'état $e$ correspond à l'état abstrait $(\lnot f_1, f_2, f_3)$ dans
l'abstraction générée.

L'abstraction générée comporte un nombre fini d'états (au plus $2^n$) car il n'y
a qu'un nombre fini de prédicats.
Le model-checking peut donc être appliqué à cette abstraction. Si une propriété
de sûreté est vérifiée dans l'abstraction, elle l'est également dans le système
concret.

Cette technique est notamment utilisée par \slam~\cite{\citeslam}.


\subsubsection{Preuve de programmes}
\label{sec:preuve}


La vérification déductive, ou ``preuve de programmes'', utilise des fondements
mathématiques et logiques pour prouver des propriétés de programmes
\cite{Hoare/69}.
Cette technique nécessite de donner au moins une postcondition à prouver,
exprimée dans un langage de spécification formelle (voir \ref{sec:speclang}).
Le calcul de la plus faible précondition \cite{Dijkstra/75} génère des
formules appelées obligations de preuve, qui sont soumises à un prouveur de
théorèmes, qui applique différentes techniques de résolution.

Contrairement au model-checking, la preuve a l'avantage d'être
indépendante de la taille de l'espace des états, et peut donc s'appliquer sur
des systèmes de grande taille et de taille infinie.
En contre-partie, cette technique requiert une expertise de l'utilisateur pour
adapter le programme à la preuve (en l'annotant par exemple) et guider le
prouveur si nécessaire.

Il existe des prouveurs automatiques tels que \simplify~\cite{\citesimplify},
\ergo~\cite{\citeergo}, \altergo~\cite{\citealtergo},
\cvcthree~\cite{\citecvcthree}, \cvcfour~\cite{\citecvcfour} et
\zthree~\cite{\citezthree}; et des
prouveurs interactifs, où la preuve est guidée par l'utilisateur, tels que
\coq~\cite{\citecoq}, \isabelle~\cite{\citeisabelle}, et \hol~\cite{\citehol}.
Certains de ces prouveurs ou assistants de preuve sont intégrés à
d'autres outils tels que \boogie~\cite{\citeboogie} ou
\escjava~\cite{\citeescjava}.
\framac intègre le greffon de preuve \Wp~\cite{\citewp} qui génère des formules
logiques à prouver à partir de la spécification d'un programme, et invoque
différents prouveurs afin de vérifier ces formules.


\subsection{Analyse dynamique}
\label{sec:AD}


L’analyse dynamique est basée sur des techniques d’exécution du programme, de
simulation d’un modèle \cite{Whitner/WSC89} ou d'exécution symbolique
\cite{Clarke/76,King/76}.

Ces techniques permettent notamment de réaliser de la génération de tests pour
un système.
Le test peut être utilisé tout au long du cycle de développement d’un
logiciel. Les tests unitaires vérifient le bon fonctionnement des différentes
entités d’un système, indépendamment les unes des autres. Les tests
d'intégration vérifient la bonne communication entre ces entités. Les tests de
validation s'assurent que les fonctionnalités correspondent au besoin de
l’utilisateur final. Enfin, les tests de non-régression vérifient que l'ajout de
nouvelles fonctionnalités ne détériore pas les anciennes fonctionnalités.

En général, les techniques de test ne sont pas exhaustives et n'explorent qu'un
sous-ensemble des chemins d'exécution du programme.
En conséquence, l’absence d’échecs lors du passage des tests n’est pas une
garantie absolue de bon fonctionnement du système.
Néanmoins, selon les critères utilisés pour la génération des tests, et selon le
niveau de couverture fourni par les tests, on peut acquérir un
certain niveau de confiance dans un système ainsi validé.

Les méthodes de test peuvent être classées en trois catégories : le test
aléatoire, le test structurel et le test fonctionnel.
Le test aléatoire consiste à générer des valeurs d'entrée du programme au
hasard.
Il ne sera pas détaillé dans cette thèse.
Nous présentons la génération de tests structurels en
partie~\ref{sec:test-structurel} et la génération de tests fonctionnels en
partie~\ref{sec:test-fonctionnel}.
Leur l'objectif est de produire des entrées pour le programme sous vérification.
Nous présentons en partie~\ref{sec:monitoring} la validation à l'exécution, qui
opère sur des programmes dont les entrées sont données.


\subsubsection{Test structurel}
\label{sec:test-structurel}


Le test structurel, ou test ``boîte blanche'', est une technique de test qui
fonde la détermination des différents cas de test sur une analyse de la
structure du code source du programme étudié. On distingue deux types de tests
structurels : le test orienté flot de contrôle et le test orienté flot de
données.

Le test orienté flot de données cherche à couvrir certaines relations entre la
définition d’une variable et son utilisation, par exemple, on peut souhaiter
couvrir toutes les lectures d'une variable suivant une écriture.

Le test orienté flot de contrôle s’intéresse quant à lui à la structure du
programme : l'ordre dans lequel les instructions sont exécutées. Il se base sur
le graphe de flot de contrôle du programme : c'est un graphe connexe orienté
avec un unique n\oe{}ud d’entrée et un unique n\oe{}ud de sortie, dont les
n\oe{}uds sont les blocs de base du programme et les arcs représentent les
branchements (conditions).
Une couverture structurelle de ce graphe est recherchée, selon un critère qui
peut être par exemple ``toutes les instructions'', ``toutes les branches''
(toutes les décisions) ou ``tous les chemins''.

\pathcrawler \cite{Williams/ASE04,\citepathcrawler} est un outil de génération
de tests structurels pour les programmes C.
C'est le générateur de tests que nous utilisons dans nos travaux.
Il est possible de l'utiliser sous la forme d'un service web :
\textsc{PathCrawler Online} \cite{\citepconline}.

\pathcrawler utilise la technique d’exécution symbolique dynamique, ou exécution
``concolique'', qui associe l’exécution concrète du programme et l’exécution
symbolique afin d’explorer les chemins du programme.
L’exécution concrète permet de confirmer que le chemin parcouru lors de
l'exécution d'un test est bien celui pour lequel le cas de test exécuté a été
généré.
L'exécution symbolique permet de mettre en relation les chemins et les sorties
du programme avec les entrées, produisant des ``prédicats de chemin''.
Un prédicat de chemin est un ensemble de contraintes sur les entrées qui
caractérisent un chemin d'exécution du programme.
Le principe de l'exécution concolique est de produire progressivement de
nouvelles entrées pour le programme sous test, dans le but d'exécuter d'autres
branches du programme.
Ce processus est répété jusqu'à ce que le code du programme soit entièrement
couvert par rapport au critère de couverture sélectionné.

Plusieurs outils se basent sur l'exécution concolique pour explorer un programme
sous test, dont \smart~\cite{\citesmart}, \pex~\cite{\citepex},
\sage~\cite{\citesage}, \cute~\cite{\citecute}, \klee~\cite{\citeklee},
\Exe~\cite{\citeexe}, et \pathcrawler~\cite{Williams/ASE04,\citepathcrawler}.
Ces outils utilisent des solveurs de contraintes pour générer des cas de test
permettant d'aboutir à une couverture souhaitée du programme par les tests.


\subsubsection{Test fonctionnel}
\label{sec:test-fonctionnel}


Le test fonctionnel, ou test ``boîte noire'', génère des jeux de test en
fonction du comportement attendu du programme, qui peut être exprimé sous la
forme d'une spécification formelle (un contrat) ou d'informations de conception
informelles (documentation, cahier des charges).
Le test fonctionnel est utilisé pour vérifier la conformité des réactions du
logiciel avec les attentes de l'utilisateur, sans connaissance du code source.
Il existe de nombreuses techniques qui se différencient par la manière de
choisir les données de test, parmi lesquelles :

\begin{description}
\item[le test de partition] \hfill \\
les valeurs d’entrées du logiciel sont regroupées en classes d’équivalence, sur
lesquelles le logiciel doit avoir le même comportement ({\em domain splitting}),
une seule valeur aléatoire est choisie dans chaque classe de la partition;
\item[le test aux limites] \hfill \\
les données de test sont choisies aux bornes des domaines de définition des
variables.
\end{description}

\gatel \cite{\citegatel} est un générateur de
tests fonctionnels qui se base sur une représentation symbolique des états du
système : le programme, les invariants et les contraintes décrivant l'objectif
de test sont exprimés dans le langage \lustre \cite{\citelustre}. Cet outil
offre la possibilité de réaliser des partitions de domaines.


\subsubsection{Validation à l'exécution}
\label{sec:monitoring}


La validation à l'exécution ou {\em runtime assertion checking} \cite{Clarke/06}
est l'évaluation de la spécification formelle d'un programme lors de son
exécution.
Cette méthode opère généralement sur une version modifiée (on dira
{\em instrumentée}) du programme.
Ainsi, si une annotation du programme initial est invalide, l'exécution du
programme instrumenté provoque une erreur, sinon l'exécution est identique à
celle du programme initial.

Contrairement au test structurel ou au test fonctionnel, la validation à
l'exécution opère sur un programme dont les entrées sont données.

\textsc{jmlc} \cite{\citejml}, \textsc{Jahob} \cite{Zee/RV07},
\textsc{SLICK} \cite{Nguyen/VMCAI08}, \textsc{APP} \cite{Rosenblum/ICSE92},
\eiffel \cite{\citeeiffel}, \spark \cite{\citespark} et le greffon \eacsltoc
\cite{\citeeacsltoc} de \framac sont des outils de validation des assertions à
l'exécution.


\subsection{Langages de spécification}
\label{sec:speclang}


Les propriétés d'un programme à vérifier sont le plus souvent exprimées dans un
langage de spécification formel \cite{Hatcliff/12}.
Le langage \eiffel \cite{\citeeiffel} embarque son propre langage de
spécification.
\spark \cite{\citespark} est un langage de spécification pour le langage Ada.
\jml (Java Modeling Language) \cite{\citejml} est un langage de spécification
pour le langage Java et \acsl (ANSI/ISO C Specification Language)
\cite{\citeacsl} est un langage de spécification pour le langage C fourni par
la plateforme \framac \cite{\citeframac}.

La plupart de ces langages conviennent aussi bien aux analyses statiques comme
la preuve qu'aux analyses dynamiques comme le {\em runtime checking}
\cite{Leavens/FMCO03, Cheon/AADEBUG05, Delahaye/SAC13, Ahrendt/FM15}.

Nous présentons plus en détail le langage \acsl et son intégration dans \framac
en partie~\ref{sec:framac}.


\subsection{La plate-forme \framac}
\label{sec:framac}


\framac \cite{\citeframac} est une plate-forme dédiée à l'analyse
des programmes C, conjointement dévelopée par le CEA LIST et Inria.
Son architecture comporte un noyau et un écosystème de greffons, rendant l’outil
extensible.
Les greffons peuvent échanger des informations et utiliser les  services fournis
par le noyau, permettant ainsi une collaboration entre différentes analyses.

\framac est basé sur \cil \cite{\citecil}, une bibliothèque qui normalise des
programmes C (ISO C99) en opérant des modifications syntaxiques : normalisation
des boucles en utilisant la structure \lstinline'while', unique
\lstinline'return' pour
chaque fonction, etc. \framac étend \cil pour supporter des annotations
dédiées portant sur le code source, exprimées dans le langage \acsl.
\acsl \cite{\citeacsl} est un langage formel de spécification
comportementale \cite{Hatcliff/12}, inspiré de \jml \cite{\citejml}, pouvant
exprimer des propriétés fonctionnelles de programmes C : préconditions,
postconditions, invariants, etc.
Les annotations du langage \acsl sont écrites en utilisant la logique
du premier ordre, et il est possible de définir ses propres fonctions et
prédicats.

La spécification d'une fonction comprend les préconditions (exprimées par une
clause \lstinline'requires') requises lors de l'appel et les postconditions
(clause \lstinline'ensures') assurées lors du retour.
Parmi ces postconditions, une clause \lstinline'assigns' indique quels sont les
emplacements mémoire qui peuvent être affectés par la fonction.

\lstinputlisting[caption={Exemple de spécification \acsl},label=lst:swap]{
  listings/swap.c}

Considérons par exemple une spécification fournie pour une fonction
\lstinline'swap' (listing~\ref{lst:swap}).
La première précondition établit que les deux arguments doivent être des
pointeurs valides, autrement dit, le déréférencement de \lstinline'a' ou de
\lstinline'b' pour la lecture ou l'écriture des valeurs pointées ne produira pas
d'erreur à l'exécution.
La seconde précondition (ligne 2) impose que les emplacements mémoire occupés
par chacune de ces variables soient disjoints et donc que leurs plages
d'adresses soient différentes.
La clause \lstinline'assigns' de la ligne 3 indique que seules les valeurs
pointées par les pointeurs \lstinline'a' et \lstinline'b' peuvent être modifiées
par la fonction.
En plus de \lstinline'\valid' et \lstinline'\separated', \acsl fournit de
nombreux prédicats et fonctions afin de décrire les états de la mémoire.
L'expression \lstinline'\at(e,l)' fait référence à la valeur de l'expression
\lstinline'e' dans l'état de la mémoire au label \lstinline'l'.
\lstinline'Pre' est un label prédéfini qui fait référence à l'état de la mémoire
avant l'exécution de la fonction.
Ainsi, les postconditions (lignes 4--5) du listing~\ref{lst:swap} signifient
qu'à la fin de la fonction, \lstinline'*a' aura la valeur que \lstinline'*b'
avait au début de la fonction, et réciproquement.

Le langage \acsl offre aussi la possibilité d'écrire des annotations dans le
code source, permettant d'exprimer des propriétés devant être vraies à un point
donné du programme : les assertions (clause \lstinline'assert').
Il est également possible d'exprimer des propriétés devant être vraies avant une
boucle et après chaque itération de cette boucle : les invariants de boucle
(clause \lstinline'loop invariant').

Les greffons peuvent valider ou invalider les propriétés \acsl et
générer des annotations \acsl.
Les annotations sont donc un moyen d'échanger des informations entre les
différentes analyses opérées par les greffons.
Par exemple, quand l'analyse de valeurs détecte une menace de division par zéro,
elle peut ajouter l'annotation \lstinline'/*@ assert x != 0; */' avant
l'opération de division par \lstinline'x', laissant à d'autres greffons la
charge de valider ou invalider cette assertion.

Parmi les greffons de \framac, nous pouvons citer \Value (analyse de valeurs par
interprétation abstraite), \Wp (vérification déductive), \pathcrawler
(génération de tests structurels), \textsc{Slicing} (simplification syntaxique),
\eacsltoc (validation d'assertions à l'exécution) et \rte (détection
d'erreurs à l'exécution potentielles).


\section{Problématique et motivations}
\label{sec:pb-motiv}


La figure~\ref{fig:motiv} présente un schéma classique de vérification des
logiciels.
Le code du logiciel est écrit par un ingénieur développement en se basant sur
une spécification informelle dont la correction n'est pas remise en cause.
La vérification de logiciels repose le plus souvent sur une spécification
formelle encodant les propriétés du programme à vérifier.
La spécification formelle est écrite par un ingénieur validation en se basant
sur la spécification informelle.
La tâche de spécification et de vérification déductive (définie en
\ref{sec:preuve}) des programmes effectuée par l'ingénieur validation est longue
et difficile et nécessite une connaissance des outils de preuve de programmes.
En effet, un échec de preuve de programme peut être dû :
\begin{itemize}
\item à une non-conformité du code par rapport à sa spécification;
\item à un contrat de boucle ou de fonction appelée  trop faible pour prouver
  une autre propriété;
\item ou à une incapacité du prouveur.
\end{itemize}
Il est souvent difficile pour l'utilisateur de décider laquelle de ces trois
raisons est la cause de l'échec de la preuve, car cette information n'est pas
(en général) donnée par le prouveur et requiert donc une revue approfondie
du code et de la spécification.

\begin{figure}[bt]
  \begin{center}
    \begin{tikzpicture}[>=latex,font=\scriptsize]
      \node[] at (0,0) (Bob) {\includegraphics[scale=0.15]{figures/user_m.png}};
      \node[below right of=Bob] {\textbf{Bob}, ingénieur développement};
      \node[draw=greenv,thick,minimum width=6.7cm,rounded corners,
        align=center] (spec) at (2,1.9) {Spécification informelle};
      \node[above of=Bob,draw,node distance=1cm,thick,
        rounded corners,minimum width=2.65cm] (code) {Code};
      \node[right of=Bob,node distance=4cm] (Alice) {
        \includegraphics[scale=0.15]{figures/user_f.png}};
      \node[below right of=Alice] {\textbf{Alice}, ingénieur validation};
      \node[above of=Alice,draw,node distance=1cm,thick,
        rounded corners,minimum width=2.65cm] (annot) {
        Spécification formelle};
      \node[draw,dotted,thick,fit=(code) (annot)] (code-annot) {};
      \node[right of=code-annot,draw,node distance=6.5cm,thick,
        rounded corners,minimum width=2.65cm,align=center] (wp) {
        Vérification déductive};
      \draw[->,thick] (code-annot.east) to[out=0,in=90] (wp);
      \draw[->,thick,color=orange] (wp.south) to[out=-90,in=0]
      node[below right=.2cm]{échec de la preuve}(Alice.east);
    \end{tikzpicture}
  \end{center}
  \caption{Processus de vérification par la preuve\label{fig:motiv}}
\end{figure}

L'objectif de cette thèse est de fournir une méthode de diagnostic automatique
des échecs de preuve afin de décider si la cause d'un échec de preuve est une
non-conformité entre le code et la spécification, ou la faiblesse d'un ou
plusieurs sous-contrats de la spécification, ou enfin une incapacité de l'outil
de vérification déductive.
Nos travaux ont donc pour but d'améliorer et de faciliter le processus de
spécification et de preuve des programmes.


\section{Contributions}
\label{sec:contrib}


Nous proposons une méthode originale d'aide à la vérification déductive, par
génération de tests structurels sur une version instrumentée du programme
d'origine.
Cette méthode consiste en deux étapes.

Premièrement, nous essayons de détecter les non-conformités du code par
rapport à la spécification.
Cette phase nécessite une traduction en C des annotations \acsl afin
d'expliciter les violations potentielles d'annotations par la création de
nouvelles branches dans le programme.
La préservation de la sémantique par cette traduction nous assure de trouver
les erreurs de conformité entre le code et la spécification par génération de
tests structurels à condition de couvrir tous les chemins d'exécution faisables
du programme.
L'aspect méthodologique de cette première étape est détaillé
dans~\cite{Petiot/TAP14} et la traduction des annotations est présentée
dans~\cite{Petiot/SCAM14}.

Deuxièmement, si le programme ne contient pas de non-conformité, nous essayons
de détecter les faiblesses de sous-contrats (contrats de boucle ou de fonction
appelée).
Cette seconde phase nécessite une traduction en C des annotations \acsl
différente de la première, car nous voulons pouvoir ``exécuter'' certains
contrats au lieu du code qu'ils spécifient.
Si aucune de ces deux phases n'a fourni de raison quant à l'échec de la preuve
et si la génération de tests a couvert tous les chemins d'exécution faisables
du programme, alors l'échec de la preuve est dû à une incapacité du prouveur,
sinon le problème reste non résolu.
La combinaison de ces deux phases de détection est présentée
dans~\cite{Petiot/unpublished15}.

Cette méthode de diagnostic des échecs de preuve par génération de tests
structurels est notre principale contribution.
Elle inclut la traduction en C des annotations \acsl pour la détection de
non-conformités, la traduction en C des annotations \acsl pour la détection de
faiblesses de sous-contrats, la justification de correction de ces traductions,
l'implémentation de notre méthode de diagnostic des échecs de preuve par le test
sous la forme d'un greffon \framac appelé \stady et des expérimentations
évaluant l'impact de la méthode sur le diagnostic des échecs de preuve.
L'outil \stady nous a notamment permis de faciliter la vérification déductive de
certains programmes \cite{Genestier/TAP15}.

Une autre contribution est la validation à l'exécution des annotations \acsl
liées au modèle mémoire, ainsi que l'implémentation d'une bibliothèque
permettant de valider ces annotations à l'exécution.
Cette contribution est détaillée dans~\cite{Kosmatov/RV13}. 


\section{Plan de la thèse}
\label{sec:plan}


Nous avons présenté le contexte de nos travaux ainsi que la problématique, nos
motivations et nos contributions.
Nous annonçons maintenant le plan de la thèse.

Un état de l'art détaillé du domaine, centré sur les combinaisons d'analyses
statiques et d'analyses dynamiques ainsi que sur l'aide à la preuve est
donné dans le chapitre~\ref{sec:state-art}.
Le chapitre~\ref{sec:lang} définit la syntaxe et la sémantique des langages de
programmation et de spécification considérés dans nos travaux : respectivement
un sous-ensemble du langage C et un sous-ensemble du langage \acsl.
Ce chapitre définit également la sémantique de ces langages.

Les chapitres suivants détaillent nos contributions.
Le chapitre~\ref{sec:traduction} présente une traduction des annotations \acsl
en C appropriée pour une détection (par génération de tests) des non-conformités
entre le code et la spécification.
Les contributions de ce chapitre ont été publiées dans
l'article~\cite{Petiot/SCAM14}.
Le chapitre~\ref{sec:runtime} aborde la validation d'annotations \acsl liées au
modèle mémoire.
Ce sont des annotations particulières que nous validons à l'exécution et non
par génération automatique de tests structurels.
Les contributions de ce chapitre ont été publiées dans
l'article~\cite{Kosmatov/RV13}.

Nous présentons notre méthode de détection des non-conformités entre le code et
la spécification au chapitre~\ref{sec:ncd}, notre méthode de détection des
faiblesses de contrats au chapitre~\ref{sec:swd}.
Puis le chapitre~\ref{sec:method} présente une méthode plus générale combinant
ces deux méthodes de détection afin de diagnostiquer les échecs de preuve de
programmes.
Les contributions du chapitre~\ref{sec:ncd} ont été publiées dans
l'article~\cite{Petiot/TAP14}.
Les contributions des chapitres~\ref{sec:swd} et~\ref{sec:method} sont
présentées dans le rapport de recherche~\cite{Petiot/unpublished15}.

Le chapitre~\ref{sec:eacsl} présente notre implémentation d'une bibliothèque C
permettant de valider à l'exécution les annotations \acsl liées au modèle
mémoire, ainsi que les résultats de nos expérimentations.
L'implémentation de notre méthode de diagnostic des échecs de preuve ainsi
que les résultats de nos expérimentations sont présentés au
chapitre~\ref{sec:stady}.

Enfin, le chapitre~\ref{sec:end} présente le bilan de nos travaux et les
différentes perspectives envisagées.

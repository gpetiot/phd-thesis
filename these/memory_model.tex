
\chapter{Modèle mémoire pour la validation d'assertion à l'exécution}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Introduction}
introduction + related work (Valgrind, AddressSanitizer, ...)

\subsection{Validation à l'exécution}

{\em Runtime Assertion Checking}

\subsection{Gestion de la mémoire en C}

{\em Memory safety}

\subsection{\textsc{Executable-acsl} (\textsc{e-acsl})}

{\textsc e-acsl} est un sous-ensemble ``exécutable'' du langage \textsc{acsl}
implémenté dans \textsc{Frama-C}. Contrairement à \textsc{e-acsl}, chaque
spécification \textsc{e-acsl} est exécutable : elle peut être évaluée à
l'exécution.\\

Le travail présenté dans ce chapitre s'appuie sur et étend \textsc{e-acsl2c}
\footnote{http://frama-c.com/eacsl.html}, un greffon de \textsc{Frama-C}. Ce
dernier traduit automatiquement un programme C annoté en un autre programme dont
l'exécution échouera si une annotation n'est pas valide. Si aucune annotation
n'est violée, le comportement du nouveau programme est exactement le même que
celui du programme d'origine.





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\section{Informations relatives à la validité et à l'initialisation}


Détaillons les annotations \textsc{acsl} que nous souhaitons prendre en compte.
Elles sont au nombre de 6 : ${\tt \backslash base\_addr}$,
${\tt \backslash block\_length}$, ${\tt \backslash offset}$,
${\tt \backslash valid}$, ${\tt \backslash valid\_read}$ et
${\tt \backslash initialized}$.

\subsection{Adresse de base d'un bloc}

${\tt \backslash base\_addr\{L\}(p)}$ retourne l'adresse de base du bloc alloué
qui contient, au label $L$, le pointeur $p$.

\begin{figure}[h]
  \begin{center}
    \begin{tikzpicture}[>=latex,font=\sffamily]
      \node [memcell] at (0,0) (A) {};
      \node [anchor=west,memcell,full] at (A.east) (B) {$bloc_1$};
      \node [anchor=west,memcell,full,minimum width=4cm] at (B.east) (C)
            {$bloc_2$};
      \node [anchor=west,memcell] at (C.east) (D) {};
      \node [anchor=west,memcell,full] at (D.east) (E) {$bloc_3$};
      \node [anchor=west,memcell] at (E.east) (F) {};
      \path (C.south)+(0,-1) node (p) {${\tt p}$};
      \path (C.south)+(-2,-1) node (basep) {${\tt \backslash base\_addr(p)}$};
      
      \draw [->,line width=1.2pt] (basep) -- (C.south west);
      \draw [->,line width=1.2pt] (p) -- (C);
    \end{tikzpicture}
  \end{center}
  \caption{Adresse de base d'un bloc}
  \label{fig:base-addr}
\end{figure}

La Fig.~\ref{fig:base-addr}
illustre ${\tt \backslash base\_addr(p)}$.

\begin{figure}[h]
\begin{lstlisting}
int main() {
  int *p = malloc(3*sizeof(int));
  //@ assert \base_addr(p+2) == p;
  free(p);
  return 0;
}
\end{lstlisting}
\caption{Exemple d'utilisation de ${\tt \backslash base\_addr}$}
\label{fig:base-addr-example}
\end{figure}

La Fig.~\ref{fig:base-addr-example}
illustre l'utilisation de ${\tt \backslash base\_addr}$, l'annotation de ce
programme est vraie.


\subsection{Longueur d'un bloc}

${\tt \backslash block\_length\{L\}(p)}$ retourne la longueur (en octets) du
bloc alloué qui contient, au label $L$, le porinteur $p$. 


\begin{figure}[h]
  \begin{center}
    \begin{tikzpicture}[>=latex,font=\sffamily]
      \node [memcell] at (0,0) (A) {};
      \node [anchor=west,memcell,full] at (A.east) (B) {$bloc_1$};
      \node [anchor=west,memcell,full,minimum width=4cm] at (B.east) (C)
            {$bloc_2$};
      \node [anchor=west,memcell] at (C.east) (D) {};
      \node [anchor=west,memcell,full] at (D.east) (E) {$bloc_3$};
      \node [anchor=west,memcell] at (E.east) (F) {};
      \path (C.south west)+(0,-1) node (p) {${\tt p}$};
      
      \draw [->,line width=1.2pt] (p) -- (C.south west);
      \draw [|<->|,line width=1.2pt]
      (C.south west) -- (C.south east)
      node [midway,below] {${\tt \backslash block\_length(p)}$};
    \end{tikzpicture}
  \end{center}
  \caption{Longueur d'un bloc}
  \label{fig:block-length}
\end{figure}

La Fig.~\ref{fig:block-length} illustre ${\tt \backslash block\_length(p)}$.

\begin{figure}[h]
\begin{lstlisting}
int main() {
  int *p = malloc(3*sizeof(int));
  //@ assert \block_length(p) == 3*sizeof(int);
  free(p);
  return 0;
}
\end{lstlisting}
\caption{Exemple d'utilisation de ${\tt \backslash block\_length}$}
\label{fig:block-length-example}
\end{figure}

La Fig.~\ref{fig:block-length-example} illustre l'utilisation de
${\tt \backslash block\_length}$, l'annotation de ce programme est vraie.


\subsection{Offset d'un pointeur dans un bloc}

${\tt \backslash offset\{L\}(p)}$ retourne le décalage entre $p$ et son adresse
de base.


\begin{figure}[h]
  \begin{center}
    \begin{tikzpicture}[>=latex,font=\sffamily]
      \node [memcell] at (0,0) (A) {};
      \node [anchor=west,memcell,full] at (A.east) (B) {$bloc_1$};
      \node [anchor=west,memcell,full,minimum width=4cm] at (B.east) (C)
            {$bloc_2$};
      \node [anchor=west,memcell] at (C.east) (D) {};
      \node [anchor=west,memcell,full] at (D.east) (E) {$bloc_3$};
      \node [anchor=west,memcell] at (E.east) (F) {};
      \path (C.south)+(0,-1) node (p) {${\tt p}$};
      
      \draw [->,line width=1.2pt] (p) -- (C);
      \draw [|<->|,line width=1.2pt]
      (C.south west) -- (C.south)
      node [midway,below] {${\tt \backslash offset(p)}$};
    \end{tikzpicture}
  \end{center}
  \caption{Offset d'un pointeur dans un bloc}
  \label{fig:offset}
\end{figure}

La Fig.~\ref{fig:offset} illustre ${\tt \backslash offset(p)}$.


\begin{figure}[h]
\begin{lstlisting}
int main() {
  int *p = maloc(3*sizeof(int));
  //@ assert \offset(p+2) == 2;
  free(p);
  return 0;
}
\end{lstlisting}
\caption{Exemple d'utilisation de ${\tt \backslash offset}$}
\label{fig:offset-example}
\end{figure}

 La
Fig.~\ref{fig:offset-example} illustre l'utilisation de
${\tt \backslash offset}$, l'annotation de ce programme est vraie.


\subsection{Validité d'un bloc}

${\tt \backslash valid\{L\}(p)}$ (respectivement
${\tt \backslash valid\_read\{L\}(p)}$) est vrai si le déréférencement de $p$
au label $L$ est autorisé en lecture et en écriture (resp. au moins en lecture).

${\tt \backslash valid\{L\}(p)}$ implique ${\tt \backslash valid\_read\{L\}(p)}$
mais l'inverse n'est pas vrai.




\begin{figure}[h]
  \begin{center}
    \begin{tikzpicture}[>=latex,font=\sffamily]
      \node [memcell] at (0,0) (A) {};
      \node [anchor=west,memcell,full] at (A.east) (B) {$bloc_1$};
      \node [anchor=west,memcell,full,minimum width=4cm] at (B.east) (C)
            {$bloc_2$};
      \node [anchor=west,memcell] at (C.east) (D) {};
      \node [anchor=west,memcell,full] at (D.east) (E) {$bloc_3$};
      \node [anchor=west,memcell] at (E.east) (F) {};
      \path (C.south)+(0,-1) node (p) {${\tt p}$};
      \path (C.south)+(0,-1.5) node {${\tt \backslash valid(p)}$};
      \path (D.south)+(0,-1) node (q) {${\tt q}$};
      \path (D.south)+(0,-1.5) node {${\tt \lnot \backslash valid(q)}$};
      
      \draw [->,line width=1.2pt] (p) -- (C);
      \draw [->,line width=1.2pt] (q) -- (D);
      
    \end{tikzpicture}
  \end{center}
  \caption{Validité d'un bloc}
  \label{fig:valid}
\end{figure}

La Fig.~\ref{fig:valid} illustre le prédicat ${\tt \backslash valid}$.

\begin{figure}[h]
\begin{lstlisting}
int main(void) {
  int *a, *b;
  //@ assert ! \valid(a);
  //@ assert ! \valid(b);
  a = malloc(sizeof(int));
  b = a;
  //@ assert \valid(a);
  //@ assert \valid(b);
  free(b);
  //@ assert ! \valid(a);
  //@ assert ! \valid(b);
  return 0;
}
\end{lstlisting}
\caption{Exemple d'utilisation du prédicat ${\tt \backslash valid}$}
\label{fig:valid-example}
\end{figure}

La Fig.~\ref{fig:valid-example} illustre l'utilisations du prédicat
${\tt \backslash valid}$. Dans ce programme toutes les assertions de validité
sont vraies.


\subsection{Initialisation des octets d'un bloc}

${\tt \backslash initialized\{L\}(p)}$ est un prédicat prenant un pointeur $p$
sur une l-value en argument. Ce prédicat est vrai si la l-value en question est
initialisée au label $L$.



\begin{figure}[h]
  \begin{center}
    \begin{tikzpicture}[>=latex,font=\sffamily]
      \node [memcell] at (0,0) (A) {};
      \node [anchor=west,memcell,full] at (A.east) (B) {$bloc_1$};
      \node [anchor=west,memcell,full,minimum width=4cm] at (B.east) (C)
            {
              \begin{tikzpicture}[>=latex,font=\sffamily]
                \node [memcell,init] at (0,0) (c1) {c1};
                \node [anchor=west,memcell,init] at (c1.east) (c2) {c2};
                \node [anchor=west,memcell,uninit] at (c2.east) (c3) {c3};
              \end{tikzpicture}
            };
      \node [anchor=west,memcell] at (C.east) (D) {};
      \node [anchor=west,memcell,full] at (D.east) (E) {$bloc_3$};
      \node [anchor=west,memcell] at (E.east) (F) {};

      \path (C.south)+(-1,-1) node (p) {${\tt p}$};
      \path (C.south)+(-2,-1.5) node {${\tt \backslash initialized(p)}$};
      \path (C.south)+(1,-1) node (q) {${\tt q}$};
      \path (C.south)+(2,-1.5) node {${\tt \lnot \backslash initialized(q)}$};
      
      \draw [->,line width=1.2pt] (p) -- (p)+(0,.5);
      \draw [->,line width=1.2pt] (q) -- (q)+(0,.5);
      
    \end{tikzpicture}
  \end{center}
  \caption{Initialisation des octets d'un bloc}
  \label{fig:initialized}
\end{figure}

La Fig.~\ref{fig:initialized} illustre le prédicat
${\tt \backslash initialized}$.


\begin{figure}[h]
\begin{lstlisting}
int main(void) {
  int *p = malloc(3*sizeof(int));
  p[0] = 0;
  //@ assert \initialized(p+0);
  //@ assert ! \initialized(p+1);
  free(p);
  return 0;
}
\end{lstlisting}
\caption{Exemple d'utilisation du prédicat ${\tt \backslash initialized}$}
\label{fig:initialized-example}
\end{figure}

La Fig.~\ref{fig:initialized-example} illustre
l'utilisation du prédicat ${\tt \backslash initialized}$. Dans ce programme,
toutes les assertions sont vraies.


~\\
Pour pouvoir traiter ces annotations \textsc{acsl}, nous devons donc conserver
pour chaque bloc les informations suivantes :
\begin{itemize}
\item l'adresse de base
\item le nombre d'octets occupés
\item le nombre d'octets initialisés
\item l'initialisation de chaque octet (un bit par octet, sauf si aucun ou tous
  les octets sont initialisés)
\item un booléen indiquant si le bloc est en lecture seule (par exemple si c'est
  une chaîne littérale)
\item un booléen indiquant s'il y a eu un accès au bloc hors bornes
\end{itemize}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\section{Enregistrements et requêtes efficaces}


\subsection{Patricia tries}

Le code instrumenté pouvant accéder et modifier fréquemment les données du
$store$, une implémentation efficace du requiert une structure de données
offrant une bonne complexité en temps et en espace. Cette structure doit être
triée : on peut avoir besoin d'accéder directement à un bloc à partir de son
adresse de base, mais aussi à partir de n'importe quelle adresse contenue dans
le bloc (donc accéder au bloc précédent). Par exemple, la fonction
${\tt \_\_base\_addr(p)}$ utilisée pour le traitement de la construction
\textsc{acsl} ${\tt \backslash base\_addr(p)}$ cherche l'adresse de base la plus
proche et inférieure à $p$ (et enfin vérifie les bornes du bloc). Cette
contrainte ne nous permet pas d'utiliser une table de hachage. Les listes
chaînées ne sont pas assez efficaces à cause de la complexité linéaire au pire
cas. Les arbres binaires de recherche non équilibrés ont aussi une complexité
linéaire au pire cas quand les données sont insérées dans un ordre strictement
monotone, ce qui est souvent le cas. Enfin, le coût du rééquilibrage de l'arbre
(pour un arbre binaire de recherche équilibré) serait amorti dans le cas où les
modifications de la structure de l'arbre sont moins nombreuses que les accès
simples; ce qui n'est pas nécessairement vrai sur les exemples de code que nous
avons instrumentés avec \textsc{e-acsl2c}.

Notre implémentation du $store$ se base sur un {\em Patricia trie}
\cite{Patricia-tries} (appelé aussi {\em radix tree} ou ``arbre à préfixe
compact'', cette structure est efficace même si l'abre n'est pas équilibré.
Les clés sont les adresses de base des blocs (c'est-à-dire des mots de 32 ou 64
bits) ou des préfixes d'adresses. Chaque feuille contient les données relatives
à un bloc en mémoire (voir section précédente pour le détail des informations
stockées). Le routage de la racine jusqu'à une feuille particulière se fait
grâce aux noeuds internes, chacun d'eux contient le plus grand préfixe commun
de l'adresse de base de ses deux fils. La Fig.~\ref{fig:insertion-Patricia-trie}
a illustre un Patricia trie (sur des adresses 8-bits pour des raisons de
simplicité).

Il contient 3 blocs dans ses feuilles (seules les adresses de base apparaissent
sur le schéma), et 2 préfixes stockés dans les noeuds internes. Le symbole
``{\tt *}'' signifie que la valeur du bit à cette position n'a pas d'importance.

La complexité théorique au pire cas d'un accès dans un Patricia trie dans notre
cas est en {\em O(k)} où $k$ est la longueur d'un mot (c'est-à-dire 32 ou 64
bits). En pratique, un programme ne pouvant allouer des blocs que dans un
espace mémoire limité, la profondeur de l'arbre est inférieure à cette borne.
De plus, contrairement aux chaînes de caractères (la première application des
Patricia tries), la comparaison des mots peut être implémentée très
efficacement par des opérations bit-à-bit.

Les données de chaque bloc n'occupent que quelques octets en mémoire, exception
faite des données d'initialisation du bloc. Le statut d'initialisation de chaque
octet est monitoré séparément
(les champs de bits ne sont pas encore supportés). Dans le pire cas (bloc
partiellement initialisé), chaque octet utilise un bit supplémentaire portant
l'information sur son initialisation. Dans le cas où tous les octets (ou aucun)
sont initialisés (on utilise un compteur d'octets initialisés), le tableau
censé contenir les bits portant l'information d'initialisation est libéré, et
cette information est donc portée uniquement par le compteur. De plus, nous
utilisons une fonction spécifique dans le cas où tous les octets d'un bloc sont
initialisés d'un coup, au lieu d'invoquer une fonction d'initialisation sur
chaque octet du bloc.


\subsection{Calcul du plus grand préfixe commun}


\begin{figure}[h]
\begin{lstlisting}
typedef unsigned char byte;
// index            0    1    2    3    4    5    6    7    8
byte  masks[] = {0x00,0x80,0xC0,0xE0,0xF0,0xF8,0xFC,0xFE,0xFF};
int longer [] = {   0,  -1,   3,  -3,   6,  -5,   7,   8,  -8};
int shorter[] = {   0,   0,   1,  -2,   2,  -4,   5,  -6,  -7};
byte gtCommonPrefixMask(byte a, byte b) {
  byte nxor = ~(a ^ b);   // a bit = 1 iff this bit is equal in a and b
  int i = 4;              // search starts in the middle of the word
  while(i > 0)            // we stop when i<=0
    if (nxor >= masks[i]) // first i bits equal,
      i = longer[i];      // try a longer prefix 
    else i = shorter[i];  // otherwise, try a shorter prefix 
  return masks[-i];       // when i<=0, masks[-i] is the answer
}
\end{lstlisting}
\caption{Calcul du plus grand préfixe commun}
\label{fig:prefix}
\end{figure}


Appelons ``masque du plus grand préfixe commun'' M de A et B. M est composé
d'une suite de $n$ ``1'', suivie d'une suite de ``0'', où $n$ est le nombre de
bits communs entre A et B. Par exemple, le plus grand préfixe commun de
A = \texttt{0110\,0111} et B = \texttt{0111\,1111} est P = \texttt{011*\,****}
et le masque du plus grand préfixe commun est M = \texttt{1110\,0000}.

Les calculs et comparaisons des préfixes ont été optimisés par un usage
intensif des opérations bit-à-bit. Le calcul du plus grand préfixe commun a lui
aussi été reconçu pour de meilleures performances. L'implémentation naïve
initiale consistait en un parcours linéaire des mots mémoire de gauche à droite
jusqu'à trouver des bits différents, de la même manière qu'on pourrait le faire 
sur des chaînes de caractères.

La version optimisée de ce calcul consiste
maintenant en une recherche dichotomique dans un tableau pré-calculé qui
contient tous les préfixes possibles. Les transitions entre les étapes de la
recherche se font en utilisant des indices pré-calculés, de manière à obtenir
le prochain masque à essayer. La Fig.~\ref{fig:prefix} illustre cette
implémentation du calcul sur des mots de 8 bits pour l'exemple. Les masques sont
stockés dans le tableau de la ligne 3. Les indices à utiliser pour tester un
masque plus long (resp. plus court) sont stockés dans le tableau ligne 4 (resp.
ligne 5). Par exemple, pour A et B définis plus haut, nxor = \texttt{1110\,0111}
et la fonction essaie i = 4, puis i = shorter[4] = 2, puis i = longer[2] = 3,
puis i = longer[3] = -3, pour finalement retourner mask[3] = \texttt{0xE0}, qui
est précisément \texttt{1110\,0000}.



\subsection{Recherche}



\subsubsection{Recherche exacte}

Cet algorithme retourne le block $B$ tel que l'adresse de base de $B$ soit égale
au pointeur passé en paramètre. On suppose que l'algorithme n'est utilisé que
lorsqu'un tel bloc existe.

Tant qu'on n'est pas sur une feuille -- on est donc sur un noeud ayant deux fils
-- on se dirige vers le fils ayant le plus grand préfixe commun avac l'adresse
passée en paramètre de l'algorithme. Quand on arrive sur une feuille, cette
dernière contient donc forcément l'adresse que l'on cherchait.

\subsubsection{Recheche du ``contenant''}

Cet algorithme retourne le block $B$ contenant l'adresse $ptr$ passée en
paramètre, tel que : $beginAddr_B \le ptr < beginAddr_B + size_B$. Si un tel
bloc n'existe pas, $null$ est renvoyé. Cet algorithme est utilisé pour des
requêtes du type ${\tt \backslash valid}$ ou ${\tt \backslash initialized}$ où
l'adresse passée en paramètre ne correspond pas forcément à l'adresse de base
d'un bloc.

Cet algorithme est similaire à celui de la recherche exacte, au détail près
qu'il faut vérifier la formule de l'encadrement de $ptr$ par $B$ quand on arrive
sur une feuille. On utilise une pile contenant les noeuds à partir desquels il
faut reprendre le parcours si la recherche n'aboutit pas. Quand on explore le
fils droit, on empile le fils gauche. Quand on arrive sur une feuille, on
vérifie l'encadrement, s'il est vérifié on a trouvé le bloc qu'on cherchait,
sinon on utilise le dernier noeud empilé (et on le dépile) s'il existe, sinon
on retourne $null$.

\subsection{Ajout}


\begin{figure}[h]
  \begin{center}
    \begin{tabular}{ccc}
      \begin{tikzpicture}[grow=down,sibling distance=18mm,level distance=6mm,
          style={font=\scriptsize}]
        \node {\texttt{0010\,****}}
        child { node[leaf] {\texttt{0010\,0110}} }
        child { node {\texttt{0010\,1***}}
          child { node[leaf] {\texttt{0010\,1001}} }
          child { node[leaf] {\texttt{0010\,1101}} }
        };
        \node at (-1.7,0) {\textbf{a)}};
      \end{tikzpicture}
& 
      \hspace{1mm} 
&
      \begin{tikzpicture}[grow=down,level 2/.style={sibling distance=17mm},
          sibling distance=35mm,level distance=6mm,style={font=\scriptsize}]
        \node {\texttt{0010\,****}}
        child { node {\texttt{0010\,011*}}
          child { node[leaf] {\texttt{0010\,0110}} }
          child { node[leaf] {\texttt{0010\,0111}} }
        }
        child { node {\texttt{0010\,1***}}
          child { node[leaf] {\texttt{0010\,1001}} }
          child { node[leaf] {\texttt{0010\,1101}} }
        };
        \node at (-3.4,0) {\textbf{b)}};
     \end{tikzpicture}   
    \end{tabular}
  \end{center}
  \vspace{-3mm}
  \caption{Exemple de Patricia trie \textbf{a)} avant,
    et \textbf{b)} après insertion de \texttt{0010\,0111}}
  \vspace{-3mm}
  \label{fig:insertion-Patricia-trie}
\end{figure}


L'ajout d'un nouvel élément à l'arbre se déroule comme suit. Si l'arbre est
vide, l'élément est ajouté à la racine. Sinon, on recherche le noeud $x$ le plus
similaire au noeud à insérer. Celui-ci sera son frère dans la nouvelle
configuration de l'arbre. Nous créons ensuite le noeud correspondant au père. Le
plus grand préfixe commun des deux fils est calculé pour le père, et les fils
sont ordonnés en fonction de leur adresse (le plus petit à gauche). Puis le
père est inséré dans l'arbre à l'ancien emplacement de $x$. Les champs de $x$ et
de l'ancien père de $x$ (s'il existe) sont également mis à jour pour maintenir
la cohérence de l'arbre. La Fig.~\ref{fig:insertion-Patricia-trie} illustre
l'insertion de l'adresse \texttt{0010\,0111} dans un arbre. L'algorithme a
déterminé que le noeud le plus similaire serait \texttt{0010\,0110}, et crée le
père correspondant : \texttt{0010\,011*}.


\subsubsection{Recherche du noeud le plus similaire}

Dès qu'on arrive sur une feuille on la renvoie. Sinon on calcule le plus grand
préfixe commun de l'adresse passée en paramètre avec le fils gauche, de même
avec le fils droit. Si l'un des préfixes est strictement supérieur à l'autre
on se dirige vers la branche correspondante, sinon on renvoie le noeud courant.



\subsection{Suppression}


\begin{figure}[h]
  \begin{center}
    \begin{tabular}{ccc}
      \begin{tikzpicture}[grow=down,level 2/.style={sibling distance=17mm},
          sibling distance=35mm,level distance=6mm,style={font=\scriptsize}]
        \node {\texttt{0010\,****}}
        child { node {\texttt{0010\,011*}}
          child { node[leaf] {\texttt{0010\,0110}} }
          child { node[leaf] {\texttt{0010\,0111}} }
        }
        child { node {\texttt{0010\,1***}}
          child { node[leaf] {\texttt{0010\,1001}} }
          child { node[leaf] {\texttt{0010\,1101}} }
        };
        \node at (-3.4,0) {\textbf{a)}};
     \end{tikzpicture}   
& 
      \hspace{1mm} 
&
       \begin{tikzpicture}[grow=down,sibling distance=18mm,level distance=6mm,
          style={font=\scriptsize}]
        \node {\texttt{0010\,****}}
        child { node[leaf] {\texttt{0010\,0110}} }
        child { node {\texttt{0010\,1***}}
          child { node[leaf] {\texttt{0010\,1001}} }
          child { node[leaf] {\texttt{0010\,1101}} }
        };
        \node at (-1.7,0) {\textbf{b)}};
      \end{tikzpicture}
    \end{tabular}
  \end{center}
  \vspace{-3mm}
  \caption{Exemple de Patricia trie \textbf{a)} avant,
    et \textbf{b)} après suppression de \texttt{0010\,0111}}
  \vspace{-3mm}
  \label{fig:suppression-Patricia-trie}
\end{figure}

La suppression d'une feuille $x$ du Patricia trie se déroule comme suit. Si cet
élément est la racine, l'arbre devient vide. Sinon, Cette feuille a un frère $y$
et un père. $x$ et son père sont supprimés, et $y$ remonte d'un niveau (et prend
donc la place du père). Enfin, les champs du nouveau père de $y$ sont mis à jour
pour maintenir la cohérence de l'arbre (le plus grand préfixe commun est
recalculé). La Fig.~\ref{fig:suppression-Patricia-trie} illustre la suppression
de l'adresse \texttt{0010\,0111} dans un Patricia trie. Ce noeud ainsi que son
père \texttt{0010\,011*} sont supprimés, et \texttt{0010\,0110} est remonté d'un
niveau.



\section{Expérimentations}


Pour évaluer notre solution, nous avons effectué plus de 300 exécutions sur
plus de 30 programmes, obtenus à partir d'une dizaine d'exemples. Nous avons
volontairement gardés des exemples plutôt courts (moins de 200 lignes de code)
car ils ont dû être annotés en \textsc{acsl} manuellement.

Nous avons mesuré le temps d'exécution du programme d'origine et du code
instrumenté par \textsc{e-acsl2c} avec différentes options, afin d'évaluer les
performances des différentes implémentations et optimisations. Des indicateurs
comme le nombre de variables, d'allocations mémoires, d'enregistrements et de
requêtes a également été enregistré.



\begin{description}

\item[Implémentation du store] \hfill \\
Pour déterminer quelle implémentation du $store$ est la plus appropriée, nous
avons comparé des implémentations utilisant : des Patricia tries, des listes
chaînées, des arbres binaires de recherche non équilibrés et des Splay trees.

Notre implémentation utilisant les Patricia tries est en moyenne 2500 fois plus
rapide que l'implémentation à base de listes chaînées, 200 fois plus rapide que
celle utilisant les arbres binaires de recherche, et 27 fois plus rapide que
celle se basant sur les Splay trees.

La version utilisant les Splay trees offre
des performances comparables (ou légèrement meilleures, jusqu'à 3 fois) sur les
exemples contenant de fréquents accès mémoire consécutifs au même bloc dans le
$store$. En revanche, sur des examples où les accès méoire consécutifs ne se
font pas sur le même bloc (une multiplication de matrices dans notre exemple),
les performances sont beaucoup moins bonnes (jusqu'à 500 fois). Ceci est dû à
la nature des Splay treees : le dernier élément accédé est remonté à la racine
de l'arbre.

\item[Calcul du plus grand préfixe commun] \hfill \\
Nous avons comparé deux implémentations de ce calcul. La première utilise un
parcours linéaire de l'adresse (bit-à-bit, de gauche à droite). La seconde
est une recherche dichotomique du meilleur préfixe dans un tableau dont le
contenu et les indices (indiquant le prochain élément à tester) sont
pré-calculés. Cette seconde implémentation s'est révélée en moyenne 2.7 fois
plus rapide que la première sur nos exemples.

\item[Capacité de détection d'erreurs] \hfill \\
Nous avons utilisé le ``test mutationnel'' pour évaluer la capacité de détection
d'erreurs en utilisant la vérification d'assertion à l'exécution avec
\textsc{Frama-C}. Nous avons considéré 5 exemples annotés et généré leurs
{\em mutants} (en appliquant une {\em mutation} sur leur code source) et leur
avons appliqué la vérification à l'exécution. Les mutations incluent :
modifications d'opérateur arithmétique numérique, modifications d'opérateur
arithmétique sur les pointeurs, modifications d'opérateur de comparaison et
modifications d'opérateur logique ($land$ et $lor$).

L'outil de génération de test \textsc{PathCrawler} \cite{PathCrawler} a été
utilisé pour produire les cas de test. Chaque mutant a été instrumenté par
\textsc{e-acsl2c} et exécuté sur chaque cas de test pour vérifier que la
spécification était satisfaite à l'exécution. Les programmes d'origine passent
toutes les vérifications à l'exécution. Lorsqu'une violation d'une annotation a
été reportée pour au moins un cas de testn le mutant est considéré comme étant
{\em tué}. La Fig.~\ref{fig:mutation-exp} illustre les résultats. Exception
faite des mutants équivalents (lorsque la mutation produit un programme
équivalent au programme d'origine), tous les mutants erronés ont été tués.

\end{description}

La Fig.~\ref{fig:mmodel-exp} contient les résultats des expérimentations
comparant les différentes implémentations du $store$ et du calcul du plus grand
préfixe commun. bS$_{10000}$ est une recherche binaire dans un tableaux de 10000
éléments. iS$_{10000}$ est un tri par insertion d'un tableau de 10000 éléments.
mM$_{n^2}$ est une multiplication de matrices $n \times n$. mI$_{n^2}$ contient
des calculs matriciels (dont inversion et multiplication) sur des  matrices
$n \times n$. qS$_n$ est un tri rapide sur un tableau de $n$ éléments.
bbS$_{10000}$ est un tri à bulles sur un tableau à 10000 éléments. m$_{30000}$ est
une fusion de deux listes chaînées de 10000 et 20000 éléments. Rbt$_{10000}$ est
une insertion/suppression de 10000 éléments dans un arbre rouge et noir. mS$_n$
est un tri fusion d'une liste chaînée de $n$ éléments. La ligne supplémentaire
``+ RTE'' de chaque exemple correspond à une application préalable du greffon
\textsc{Rte} qui génère des assertions qui sont vraies si le programme ne
contient pas d'erreur à l'exécution.

Les colonnes ont la signification suivante : \danger contient le nombre
d'alarmes du programme,  $\emptyset$ contient le temps d'exécution du programme
original, bst correspond à l'implémentation par arbres binaires de recherche,
mask est le nombre de fois qu'est effectué le calcul du plus grand préfixe
commun, sb est le nombre d'insertion dans le $store$, Pt correspond à
l'implémentation par Patricia tries, St correspond à l'implémentation par Splay
trees. L'exposant $^1$ (respectivement $^2$) correspond aux expérimentations
sans (resp. avec) application d'une analyse statique $Dataflow$ permettant de
n'instrumenter que ce qui est nécessaire \cite{TODO}. L'indice $_1$ (resp. $_2$)
correspond à l'implémentation non optimisée (resp. optimisée) du calcul du
plus grand préfixe commun pour l'implémentation utilisant les Patricia tries.

{\color{red} analyse des résultats, confirmation des hypothèses ?}


\begin{landscape}
\begin{figure}[h]
  \centering
%\begin{tiny}
  \begin{tabular}{|l|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
    \hline
     & \danger & $\emptyset$ & list$^1$ & list$^2$ & bst$^1$ & bst$^2$ & Pt$_1^1$ & mask$^1$ & sb$^1$ & Pt$_2^1$ & Pt$_1^2$ & mask$^2$ & sb$^2$ & Pt$_2^2$ & St$^1$ & St$^2$ & valgrind \\
    \hline
    bS$_{10000}$ &22 &\multirow{2}{*}{.01} &1.10 &0.50 &1.14 &0.64 &1.55 &99 &16 &1.55 &0.57 &0 &1 &0.55 &1.39 &0.61 &\multirow{2}{*}{0.27}\\
+ RTE &41 &&1.10 &0.51 &1.14 &0.62 &1.59 &109 &16 &1.59 &0.53 &0 &1 &0.53 &1.39 &0.64 &\\
    \hline
    iS$_{10000}$ &5 &\multirow{2}{*}{.12} &2.29 &0.12 &1.83 &0.12 &2.89 &170k &20k &2.91 &0.12 &0 &0 &0.12 &2.46 &0.12 &\multirow{2}{*}{2.81}\\
+ RTE &24 &&3.52 &1.27 &2.89 &1.26 &3.99 &170k &20k &3.86 &1.25 &0 &0 &1.25 &3.46 &1.30 &\\
    \hline
    mM$_{100^2}$ &0 &\multirow{2}{*}{.01} &2.29 &0.73 &2.94 &1.15 &0.14 &17k &1k &0.14 &0.10 &5k &612 &0.09 &1.07 &0.98 &\multirow{2}{*}{0.34}\\
+ RTE &82 &&13.17 &10.66 &21.92 &17.39 &2.78 &18k &1k &3.00 &2.64 &5k &612 &2.82 &75.97 &73.62 &\\

    \hline
    mM$_{150^2}$ &0 &\multirow{2}{*}{.01} &13.23 &3.96 &15.65 &6.20 &0.54 &21k &2k &0.51 &0.36 &9k &912 &0.35 &5.86 &5.64 &\multirow{2}{*}{0.48}\\
+ RTE &82 &&72.36 &58.48 &110.70 &90.43 &10.77 &24k &2k &9.01 &8.57 &9k &912 &8.75 &403.50 &398.60 &\\
    \hline
    mI$_{100^2}$ &2 &\multirow{2}{*}{.01} &22.51 &0.10 &7.74 &0.13 &0.09 &68k &5k &0.08 &0.01 &7k &609 &0.01 &0.19 &0.10 &\multirow{2}{*}{0.35}\\
+ RTE &155 &&28.96 &4.22 &13.67 &5.48 &0.54 &73k &5k &0.55 &0.53 &7k &611 &0.47 &26.37 &26.16 &\\

    \hline
    mI$_{150^2}$ &2 &\multirow{2}{*}{.02} &130.04 &0.34 &40.35 &0.45 &0.28 &99k &8k &0.27 &0.02 &12k &909 &0.02 &0.68 &0.34 &\multirow{2}{*}{0.47}\\
+ RTE &155 &&153.30 &21.54 &73.55 &29.94 &2.00 &105k &8k &1.90 &1.42 &12k &911 &1.53 &146.15 &145.80 &\\

    \hline
    qS$_{1000}$ &15 &\multirow{2}{*}{.01} &12.70 &2.08 &1.76 &0.59 &0.33 &1M &92k &0.06 &0.13 &683k &39k &0.02 &0.02 &0.01 &\multirow{2}{*}{0.27}\\
+ RTE &32 &&12.38 &2.13 &1.64 &0.56 &0.38 &1M &92k &0.12 &0.14 &727k &39k &0.04 &0.03 &0.02 &\\

    \hline
    qS$_{2000}$ &15 &\multirow{2}{*}{.01} &85.99 &11.31 &8.39 &2.78 &0.71 &3M &198k &0.14 &0.28 &1M &84k &0.05 &0.03 &0.02 &\multirow{2}{*}{0.27}\\
+ RTE &32 &&81.65 &11.15 &7.72 &2.67 &1.13 &4M &198k &0.48 &0.36 &1M &84k &0.13 &0.05 &0.02 &\\
    \hline
    bbS$_{10000}$ &4 &\multirow{2}{*}{.22} &13.78 &1.02 &16.84 &1.67 &117.47 &499M &49M &22.36 &1.57 &30 &7 &1.54 &8.80 &1.67 &\multirow{2}{*}{3.36}\\
+ RTE &16 &&23.08 &4.64 &30.69 &7.16 &107.05 &599M &49M &32.58 &7.26 &29 &7 &6.90 &17.29 &7.21 &\\
    \hline
    m$_{30000}$ &2 &\multirow{2}{*}{.01} &412.10 &11.38 &176.35 &11.01 &1.11 &5M &420k &0.26 &0.30 &1M &60k &0.06 &0.08 &0.01 &\multirow{2}{*}{0.45}\\
+ RTE &49 &&451.58 &101.33 &219.12 &94.80 &1.15 &5M &420k &0.29 &0.47 &2M &130k &0.14 &0.10 &0.05 &\\

    \hline
    Rbt$_{10000}$ &0 &\multirow{2}{*}{.01} &47.39 &0.28 &48.44 &0.27 &0.32 &1M &159k &0.09 &0.03 &151k &10k &0.01 &0.59 &0.01 &\multirow{2}{*}{0.51}\\
+ RTE &270 &&120.02 &101.69 &165.77 &145.20 &0.47 &1M &159k &0.30 &0.39 &979k &119k &0.27 &18.82 &19.59 &\\
    \hline
mS$_{1000}$ &7 &\multirow{2}{*}{.01} &6.45 &0.34 &6.32 &0.11 &0.32 &1M &95k &0.07 &0.06 &331k &18k &0.01 &0.02 &0.01 &\multirow{2}{*}{0.27}\\
+ RTE &45 &&6.82 &1.35 &7.98 &0.38 &0.34 &1M &95k &0.10 &0.13 &701k &38k &0.04 &0.02 &0.01 &\\
        \hline
mS$_{5000}$ &7 &\multirow{2}{*}{.01} &362.87 &11.00 &218.01 &3.43 &2.28 &11M &562k &0.76 &0.43 &2M &106k &0.09 &0.14 &0.03 &\multirow{2}{*}{0.27}\\
+ RTE &45 &&371.40 &50.94 &290.88 &10.34 &2.46 &11M &562k &0.80 &0.83 &4M &218k &0.22 &0.16 &0.08 &\\

    \hline
mS$_{10000}$ &7 &\multirow{2}{*}{.01} &3624.01 &47.94 &1673.00 &16.10 &6.46 &23M &1M &2.75 &1.00 &5M &223k &0.21 &0.31 &0.08 &\multirow{2}{*}{0.27}\\
+ RTE &45 &&3406.43 &257.18 &2086.32 &46.22 &6.30 &23M &1M &2.66 &1.83 &9M &457k &0.51 &0.35 &0.18 &\\
\hline
mS$_{50000}$ &7 &\multirow{2}{*}{.01} &$\infty$ &3847.72 &$\infty$ &1100.93 &135.54 &146M &6M &111.22 &6.90 &33M &1M &1.65 &2.08 &0.58 &\multirow{2}{*}{0.63}\\
+ RTE &45 &&$\infty$ &25554.08 &$\infty$ &2781.90 &118.86 &145M &6M &95.74 &11.64 &54M &2M &3.37 &2.18 &1.15 &\\
\hline
mS$_{100000}$ &7 &\multirow{2}{*}{.01} &$\infty$ &$\infty$ &$\infty$ &$\infty$ &631.41 &296M &14M &559.93 &13.55 &70M &2M &3.35 &4.03 &1.15 &\multirow{2}{*}{0.27}\\
+ RTE &45 &&$\infty$ &$\infty$ &$\infty$ &$\infty$ &573.47 &308M &14M &513.85 &25.02 &116M &5M &7.63 &4.68 &2.50 &\\
\hline
  \end{tabular}
%\end{tiny}
  \caption{Comparaison des différentes implémentations du $store$}
\end{figure}
\label{fig:mmodel-exp}
\end{landscape}






\begin{figure}[t]
  \centering
  \begin{tabular}{|c|c|c|c|c|c|c|}
    \hline
    & alarmes & mutants & équivalents & tués & \% erronés tués \\
    \hline
    fibonacci & 19  & 27 & 2 & 25 & 100\% \\
    \hline
    bubbleSort & 15  & 44 & 2 & 42 & 100\% \\
    \hline
    insertionSort & 10  & 39 & 3 & 36 & 100\% \\
    \hline
    binarySearch & 7 & 38 & 1 & 37 & 100\% \\
    \hline
    merge & 5 & 92 & 5 & 87 & 100\% \\
    \hline
  \end{tabular}
  \vspace{-2mm}
  \caption{Capacité de détection d'erreurs}
  \vspace{-2mm}
  \label{fig:mutation-exp}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%ù


\section{Conclusion}
conclusion + future work + application dans le greffon PathCrawler (transition
avec le chapitre suivant)

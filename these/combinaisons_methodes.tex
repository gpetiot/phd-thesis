
\chapter{Combinaisons de méthodes}

\section{\textsc{DyTa}}

\textsc{DyTa} \cite{DyTa} est un outil combinant une phase d'analyse statique et
une phase d'analyse dynamique. \textsc{Code Contracts} \cite{CodeContracts} est
utilisé pour spécifier des pré/post-conditions et des invariants de programmes
C\#, il identifie également les bugs potentiels (violations de contrat) par
interprétation abstraite.\\

\textsc{DyTa} instrumente ensuite le programme pour rajouter des instructions
assurant le rôle de pré-conditions, pour ne pas générer de cas de test qui n'ont
aucune chance de produire d'erreur à l'exécution. L'instrumentation rajoute
également des points de contrôle à l'endroit des instructions signalées par
l'analyse statique, afin de guider l'exécution symbolique dynamique du programme
par \textsc{Pex} \cite{PEX}. Cette étape est semblable à l'instrumentation
opérée par \textsc{Sante} \cite{SANTE} pour rajouter des points de contrôle afin
de guider l'exécution concolique du programme par \textsc{PathCrawler}
\cite{PathCrawler}.\\

L'analyse statique du graphe du flot de contrôle du programme permet à
\textsc{DyTa} de calculer les points de contrôle à partir desquels les alarmes
(instructions potentiellement dangereuses) sont inatteignables. La génération
dynamique de tests réduit le nombre de faux positifs de l'analyse statique, et
cette dernière guide l'exploration pour la génération dynamique de tests.

\section{Vérification collaborative et test}

Cette méthode \cite{collaborative-verification} part du constat que la plupart
des outils de vérifications statiques (outils utilisant simplement des
heuristiques, outils d'interprétation abstraite, model-checkers, ou outils de
preuve) font des compromis afin d'améliorer les performances, de réduire le
nombre de faux positifs ou de limiter l'effort à fournir pour annoter le
programme. Cela se traduit par la supposition d'une propriété tout au long de
l'analyse dy programme (par exemple qu'un certains type d'erreurs ne peut pas
se produire), cette propriété n'est pas vérifiée par l'analyseur. Ceci
implique que de tels analyseurs ne peuvent garantir l'absence d'erreurs dans un
programme. Si un analyseur fait un compromis en supposant une propriété, il
faut utiliser un autre analyseur capable de valider cette propriété.\\

Cette méthode propose d'exprimer les compromis dans un langage de contrats,
afin de faciliter la collaboration entre plusieurs outils d'analyse statique
et permettant de décrire le fait qu'un assertion ait été complètement vérifiée
par un analyseur ou partiellement vérifiée sous certaines hypothèses.\\

Pour faciliter la vérification statique du programme, l'utilisateur doit au
préalable ajouter des annotations (invariants de boucle par exemple). Les
propriétés qui n'ont pas été vérifiées statiquement sont validées par des tests
unitaires. Le programme est instrumenté afin de rajouter des vérifications à
l'exécution pour guider la génération de contre-exemples. \textsc{Pex}
\cite{PEX} est utilisé pour générer des cas de test par exécution concolique,
mettant en évidence des contre-exemples. L'utilisateur peut décider de
privilégier l'analyse statique ou le test selon qu'il spécifie ou non son
programme.\\

Cette combinaison d'analyse statique, d'une instrumentation et du test est
comparable à \textsc{Sante} \cite{SANTE}, bien qu'il manque l'étape de slicing
qui permet à \textsc{Sante} d'économiser du temps sur l'analyse dynamique. En
revanche, cette méthode présente l'avantage de combiner plusieurs analyseurs
statiques et de vérifier partiellement des propriétés, ce qui n'est pas encore
possible avec \textsc{Sante}.

\section{Vérification de propriétés décrites par des automates finis}

Cette méthode \cite{checking-prop-state-machines} combine une instrumentation du
code source, une étape de {\em slicing} et une exécution symbolique.
L'instrumentation rajoute des instructions simulant le comportement de
l'automate fini correspondant au programme, dont les états correspondent aux
propriétés du programme à vérifier.
Le {\em slicing} est appliqué pour réduire la taille du programme, on ne
conserve que le code relatif aux états d'erreur de l'automate. Le programme
simplifié doit être équivalent au programme instrumenté en ce qui concerne
l'atteignabilité des états d'erreur de l'automate.
L'exécution symbolique du programme par \textsc{Klee} \cite{KLEE} va permettre
de mettre en évidence des contre-exemples pour ces propriétés.\\

L'utilisation du {\em slicing} afin de réduire la portion de code analysée
(et donc le nombre de chemins d'exécution) par l'exécution symbolique est
similaire à \textsc{Sante} \cite{SANTE}. En revanche, cette méthode ne semble
pas applicable quel que soit le type d'erreur.
\cite{checking-prop-state-machines} prend l'exemple de verrous à poser sur des
variables du programme. L'instrumentation repère des motifs bien précis dans le
programme et le code généré est spécifique à ce type d'erreur. Contrairement à
\textsc{Sante}, cette méthode n'applique pas d'analyse statique plus générale
(pouvant lever différents types d'alarmes) avant l'instrumentation.

\section{Localisation d'erreurs par slicing guidé par la trace d'exécution}

Cette méthode \cite{fault-localization} utilise un {\em slicing} arrière à
partir d'une instruction de déréférencement produisant une {\em Null Pointer
Exception} (en Java). Le {\em slicing} est guidé par la trace du programme
fournissant la pile des appels de méthode n'ayant pas terminé. Une analyse
statique des pointeurs est ensuite opérée sur le programme slicé afin de
déterminer si chacun des pointeurs peut être ${\tt NULL}$. Puis une analyse
d'alias est opérée afin d'augmenter la précision de l'analyse statique.\\

Contrairement à \textsc{Sante} \cite{SANTE} qui commence par utiliser une
analyse statique, dont le résultat paramètre le {\em slicing}, puis termine par
une analyse dynamique; cette méthode commence par une analyse dynamique, dont
le résultat paramètre le {\em slicing}, puis termine par une analyse statique.

\section{\textsc{Blast}}

Cet outil \cite{BLAST} vérifie les propriétés temporelles de sûreté d'un
programme C, ou met en évidence un chemin d'exécution violant une propriété. Le
raffinement des abstractions du programme est basé sur une abstraction par
prédicat et la découverte des prédicats se fait par interpolation. C'est une
implémentation de la méthode \textsc{Cegar} \cite{CEGAR} tout comme
\textsc{Slam} \cite{SLAM} et \textsc{Magic} \cite{MAGIC}. La génération des cas
de test se fait par exécution symbolique. Le model-checking est incrémental :
les résultats partiels sont réutilisés afin de pouvoir passer à l'échelle.\\

\textsc{Blast} ne traite ni les débordements arithmétiques ni les opérations
bit-à-bit, et considère que toutes les opérations arithmétiques sur les
pointeurs sont sûres. Le langage d'invariants utilisé pour décrire les
propriétés ne contient pas de quantifieurs, contrairement à \textsc{Acsl}
\cite{ACSL}.

\section{\textsc{Smart}}

Cet outil \cite{SMART} (basé sur son prédécesseur \textsc{Dart} \cite{DART})
génère des tests par exécution concolique. Pour résoudre le problème de
l'explosion du nombre de chemins, il va calculer à la demande des résumés de
fonction qui sont des pré-conditions et post-conditions pour chaque fonction
(contraintes sur les variables en entrée et en sortie). Ces résumés vont être
réutilisés si possible afin d'éviter de ré-exécuter la fonction correspondante.
La génération de ces résumés est présentée comme se faisant par ``analyse
statique interprocédurale'' mais se rattacherait plutôt à une analyse dynamique
car utilisant une exécution symbolique (et résolution de contraintes).

\section{\textsc{Synergy}, \textsc{Dash} et \textsc{Yogi}}

\textsc{Synergy} \cite{SYNERGY} est un algorithme combinant du test (essayer
d'atteindre un état d'erreur) et une abstraction (trouver une abstraction
suffisamment précise montrant qu'aucun chemin ne peut atteindre un état
d'erreur). La sous-approximation du test et la sur-approximation de
l'abstraction sont raffinées de manière itérative. L'abstraction est utilisée
pour guider la génération de tests. Les tests sont utilisés pour décider
{\em où} raffiner l'abstraction.\\

Les états de l'abstraction, les régions, sont des classes d'équivalence des
états du programme concret. S'il n'existe aucun chemin de la région initiale
vers une région d'erreur, alors il n'existe aucune suite de transitions
concrètes menant d'un état initial concret à un état d'erreur concret.\\

\textsc{Dash} \cite{DASH} est une évolution de \textsc{Synergy}, prenant en
compte les appels de procédure et les pointeurs (contrairement à
\textsc{Synergy}). \textsc{Dash} raffine l'abstraction en utilisant uniquement
les relations d'alias mises en évidence par les tests. La génération de tests
guide non seulement {\em où} raffiner l'abstraction, mais aussi {\em comment}
la raffiner. Cet algorithme est implémenté dans l'outil \textsc{Yogi}
\cite{YOGI}.

\section{\textsc{Sage}}

Cet outil \cite{SAGE} utilise une analyse dynamique uniquement afin de générer
des tests pour des programmes au format binaire x86. Il combine une exécution
symbolique à du {\em fuzz testing}. Une première exécution avec des entrées
valides permet de récupérer une trace d'exécution du programme. L'exécution
symbolique de cette trace permet de collecter les contraintes du chemin
d'exécution. De nouveaux chemins sont générés par négation des contraintes,
à la manière de \textsc{PathCrawler} \cite{PathCrawler} et autres outils
similaires.

\section{\textsc{Smash}}

Cet outil \cite{SMASH} combine une abstraction par prédicats et une génération
dynamique de tests (par exécution concolique). Pour chaque fonction, un résumé
des informations de type $may$ (vraies pour toutes les exécutions, permettant de
prouver l'absence d'erreurs) et un résumé des informations de type $must$
(vraies pour quelques exécutions uniquement, permettant de prouver l'existence
d'erreurs) sont calculés à la demande. L'analyse statique ($may$) et l'analyse
dynamique ($must$) se font simultanément et utilisent toutes deux les résumés
$may$ ($\lnot may$ pour des raisons techniques) et les résumés $must$.\\

Les résumés $\lnot may$ et $must$ sont progressivement raffinés pour chaque
fonction, afin de prouver qu'une propriété n'est jamais violée (si un résumé
$\lnot may$ est applicable), ou de mettre en évidence une exécution violant une
propriété (si un résumé $must$ est applicable). Par construction, il n'est pas
possible que les deux résumés soient applicables.\\

Positionnement de \textsc{Smash} \cite{SMASH} par rapport aux autres outils de
Microsoft :
\begin{shaded}
`` The \textsc{Smash} \cite{SMASH} algorithm generalizes and extends several
existing algorithms. \textsc{Slam} \cite{SLAM} performs a compositional $may$
analysis using predicate abstraction and partition refinement, but does not
perform a $must$ analysis. \textsc{Smart} \cite{SMART} performs a compositional
$must$ analysis, extending the non-compositional $must$ analysis of
\textsc{Dart} \cite{DART}, but does not perform a $may$ analysis.
\textsc{Synergy} \cite{SYNERGY} combines \textsc{Slam} \cite{SLAM} and
\textsc{Dart} \cite{DART} for intraprocedural analysis only. \textsc{Dash}
\cite{DASH} performs an interprocedural $may-must$ analysis, extending the
intraprocedural \textsc{Synergy} \cite{SYNERGY} algorithm, but is
non-compositional, i.e., it does not memoize (cache) intermediate results in the
form of reusable summaries. ''
\end{shaded}

La figure~\ref{fig:microsoft-summary} résume graphiquement ces outils.



%% GRAPHIC SUMMARY

\begin{figure}
  \centering
  \begin{tikzpicture}
    % SLAM
    \node at (0, 5) {\textsc{Slam}};
    \node at (0, 4.5) {$may$};
    \node[draw,ellipse,line width=.25mm,minimum width=1.5cm,minimum height=2cm]
    at (0, 4.75) {};

    % DART
    \node at (7, 5) {\textsc{Dart}};
    \node at (7, 4.5) {$must$ $\lnot$comp};
    \node[draw,ellipse,line width=.25mm,minimum width=2.5cm,minimum height=2cm]
    at (7, 4.75) {};

    % SMART
    \node at (10, 5) {\textsc{Smart}};
    \node at (10, 4.5) {$must$ comp};
    \node[draw,ellipse,line width=.25mm,minimum width=6cm,minimum height=6cm]
    at (8.5, 3.75) {};

    % SYNERGY
    \node at (3, 5) {\textsc{Synergy}};
    \node at (3, 4.5) {$may+must$ intra-proc};
    \node[draw,ellipse,line width=.25mm,minimum width=9cm,minimum height=4cm]
    at (3.75, 4.75) {};

    % DASH
    \node at (3, 2.5) {\textsc{Dash} + \textsc{Yogi}};
    \node at (3, 2) {$may+must$ inter-proc $\lnot$comp};
    \node[draw,ellipse,line width=.25mm,minimum width=9cm,minimum height=8cm]
    at (3.75, 4.75) {};

    % SMASH
    \node at (4, 0.5) {\textsc{Smash}};
    \node at (4, 0) {$may+must$ inter-proc comp};
    \node[draw,ellipse,line width=.25mm,minimum width=12.5cm,
      minimum height=12cm] at (5.25, 3.75) {};
  \end{tikzpicture}
  \caption{Résumé des outils de Microsoft}
  \label{fig:microsoft-summary}
\end{figure}





\section{Analyses statique et dynamique pour la génération d'invariants}

Cette méthode \cite{fromTestsToProofs} propose une solution au problème du
passage à l'échelle de la génération d'invariants (de programmes impératifs) par
résolution de contraintes. Les invariants arithmétiques linéaires sont générés
d'après les informations obtenues par interprétation abstraite du programme, par
exécution concrète et par exécution symbolique du programme. Ces informations
permettent de générer des contraintes qui vont permettre au solveur de
contraintes de simplifier le système de contraintes et de réduire l'espace de
recherche.

\section{\textsc{Cegar} : Raffinement d'abstraction guidé par des
  contre-exemples}

Le raffinement d'abstraction guidé par des contre-exemples \cite{CEGAR} associe
l’abstraction par prédicats et le model-checking : une abstraction du programme
est générée à partir d’un ensemble de prédicats et invariants. Si le
model-checking prouve la correction du système abstrait, alors le système
concret l'est également. Si le model-checking ne peut pas établir qu'une
propriété est satisfaite, il faut déterminer si elle est présente dans le
système concret. Si c'est le cas, un bug a été trouvé. Sinon il s'agit d'un
contre-exemple. De nouveaux prédicats vont être créés pour raffiner
l'abstraction afin que ce contre-exemple soit absent de l'abstraction, et ainsi
de suite. Ce processus peut ne pas terminer. Plusieurs outils de vérification se
basent sur cette méthode, parmi lesquels \textsc{Blast} \cite{BLAST},
\textsc{Magic} \cite{MAGIC} et \textsc{Slam} \cite{SLAM}.\\

Cette approche élimine les contre-exemples un par un, l'abstraction ainsi
générée peut donc mettre un certain temps avant de converger vers une forme
acceptable. Une amélioration a été proposée afin d'accélérer la convergence du
raffinement de l'abstraction : \textsc{Cegaar} \cite{CEGAAR}. Cette technique
élimine une infinité de contre-exemples (traces infaisables) de la forme
$\alpha . \lambda^* . \beta$ en une seule étape, où $\lambda$ correspond à une
ou plusieurs exécutions d'une boucle.

\section{\textsc{DSD-Crasher}}

L'outil \textsc{DSD-Crasher} \cite{DSD-Crasher} combine une génération
d'invariants par génération de tests et des techniques d'apprentissage
\cite{discover-invariants} et une analyse statique signalant des alarmes qui
seront confirmées par un générateur de tests \cite{JCrasher}. Les invariants
détectés permettent de guider la classification d'alarmes et la génération de
tests, ce qui rend l'outil très dépendant de leur qualité.


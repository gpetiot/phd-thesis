
\chapter{Combinaisons de méthodes}

\section{\textsc{DyTa}}

\textsc{DyTa} \cite{DyTa} est un outil combinant une phase d'analyse statique et
une phase d'analyse dynamique. \textsc{Code Contracts} \cite{CodeContracts} est
utilisé pour spécifier des pré/post-conditions et des invariants de programmes
C\#, il identifie également les bugs potentiels (violations de contrat) par
interprétation abstraite.\\

\textsc{DyTa} instrumente ensuite le programme pour rajouter des instructions
assurant le rôle de pré-conditions, pour ne pas générer de cas de test qui n'ont
aucune chance de produire d'erreur à l'exécution. L'instrumentation rajoute
également des points de contrôle à l'endroit des instructions signalées par
l'analyse statique, afin de guider l'exécution symbolique dynamique du programme
par \textsc{Pex} \cite{PEX}. Cette étape est semblable à l'instrumentation
opérée par \textsc{Sante} \cite{SANTE} pour rajouter des points de contrôle afin
de guider l'exécution concolique du programme par \textsc{PathCrawler}
\cite{PathCrawler}.\\

L'analyse statique du graphe du flot de contrôle du programme permet à
\textsc{DyTa} de calculer les points de contrôle à partir desquels les alarmes
(instructions potentiellement dangereuses) sont inatteignables. La génération
dynamique de tests réduit le nombre de faux positifs de l'analyse statique, et
cette dernière guide l'exploration pour la génération dynamique de tests.

\section{Vérification collaborative et test}

Cette méthode \cite{collaborative-verification} part du constat que la plupart
des outils de vérifications statiques (outils utilisant simplement des
heuristiques, outils d'interprétation abstraite, model-checkers, ou outils de
preuve) font des compromis afin d'améliorer les performances, de réduire le
nombre de faux positifs ou de limiter l'effort à fournir pour annoter le
programme. Cela se traduit par la supposition d'une propriété tout au long de
l'analyse dy programme (par exemple qu'un certains type d'erreurs ne peut pas
se produire), cette propriété n'est pas vérifiée par l'analyseur. Ceci
implique que de tels analyseurs ne peuvent garantir l'absence d'erreurs dans un
programme. Si un analyseur fait un compromis en supposant une propriété, il
faut utiliser un autre analyseur capable de valider cette propriété.\\

Cette méthode propose d'exprimer les compromis dans un langage de contrats,
afin de faciliter la collaboration entre plusieurs outils d'analyse statique
et permettant de décrire le fait qu'un assertion ait été complètement vérifiée
par un analyseur ou partiellement vérifiée sous certaines hypothèses.\\

Pour faciliter la vérification statique du programme, l'utilisateur doit au
préalable ajouter des annotations (invariants de boucle par exemple). Les
propriétés qui n'ont pas été vérifiées statiquement sont validées par des tests
unitaires. Le programme est instrumenté afin de rajouter des vérifications à
l'exécution pour guider la génération de contre-exemples. \textsc{Pex}
\cite{PEX} est utilisé pour générer des cas de test par exécution concolique,
mettant en évidence des contre-exemples. L'utilisateur peut décider de
privilégier l'analyse statique ou le test selon qu'il spécifie ou non son
programme.\\

Cette combinaison d'analyse statique, d'une instrumentation et du test est
comparable à \textsc{Sante} \cite{SANTE}, bien qu'il manque l'étape de slicing
qui permet à \textsc{Sante} d'économiser du temps sur l'analyse dynamique. En
revanche, cette méthode présente l'avantage de combiner plusieurs analyseurs
statiques et de vérifier partiellement des propriétés, ce qui n'est pas encore
possible avec \textsc{Sante}.

\section{Vérification de propriétés décrites par des automates finis}

Cette méthode \cite{checking-prop-state-machines} combine une instrumentation du
code source, une étape de {\em slicing} et une exécution symbolique.
L'instrumentation rajoute des instructions simulant le comportement de
l'automate fini correspondant au programme, dont les états correspondent aux
propriétés du programme à vérifier.
Le {\em slicing} est appliqué pour réduire la taille du programme, on ne
conserve que le code relatif aux états d'erreur de l'automate. Le programme
simplifié doit être équivalent au programme instrumenté en ce qui concerne
l'atteignabilité des états d'erreur de l'automate.
L'exécution symbolique du programme par \textsc{Klee} \cite{KLEE} va permettre
de mettre en évidence des contre-exemples pour ces propriétés.\\

L'utilisation du {\em slicing} afin de réduire la portion de code analysée
(et donc le nombre de chemins d'exécution) par l'exécution symbolique est
similaire à \textsc{Sante} \cite{SANTE}. En revanche, cette méthode ne semble
pas applicable quel que soit le type d'erreur.
\cite{checking-prop-state-machines} prend l'exemple de verrous à poser sur des
variables du programme. L'instrumentation repère des motifs bien précis dans le
programme et le code généré est spécifique à ce type d'erreur. Contrairement à
\textsc{Sante}, cette méthode n'applique pas d'analyse statique plus générale
(pouvant lever différents types d'alarmes) avant l'instrumentation.

\section{Localisation d'erreurs par slicing guidé par la trace d'exécution}

Cette méthode \cite{fault-localization} utilise un {\em slicing} arrière à
partir d'une instruction de déréférencement produisant une {\em Null Pointer
Exception} (en Java). Le {\em slicing} est guidé par la trace du programme
fournissant la pile des appels de méthode n'ayant pas terminé. Une analyse
statique des pointeurs est ensuite opérée sur le programme slicé afin de
déterminer si chacun des pointeurs peut être ${\tt NULL}$. Puis une analyse
d'alias est opérée afin d'augmenter la précision de l'analyse statique.\\

Contrairement à \textsc{Sante} \cite{SANTE} qui commence par utiliser une
analyse statique, dont le résultat paramètre le {\em slicing}, puis termine par
une analyse dynamique; cette méthode commence par une analyse dynamique, dont
le résultat paramètre le {\em slicing}, puis termine par une analyse statique.

\section{\textsc{Blast}}

Cet outil \cite{BLAST} vérifie les propriétés temporelles de sûreté d'un
programme C, ou met en évidence un chemin d'exécution violant une propriété. Le
raffinement des abstractions du programme est basé sur une abstraction par
prédicat et la découverte des prédicats se fait par interpolation. C'est une
implémentation de la méthode \textsc{Cegar} \cite{CEGAR} tout comme
\textsc{Slam} \cite{SLAM} et \textsc{Magic} \cite{MAGIC}. La génération des cas
de test se fait par exécution symbolique.\\

\textsc{Blast} ne traite ni les débordements arithmétiques ni les opérations
bit-à-bit, et considère que toutes les opérations arithmétiques sur les
pointeurs sont sûres. Le langage d'invariants utilisé pour décrire les
propriétés ne contient pas de quantificateurs, contrairement à \textsc{Acsl}
\cite{ACSL}.

\section{\textsc{Smart}}

Cet outil \cite{SMART} (basé sur son prédécesseur \textsc{Dart} \cite{DART})
génère des tests par exécution concolique. Pour résoudre le problème de
l'explosion du nombre de chemins, il va calculer à la demande des résumés de
fonction qui sont des pré-conditions et post-conditions pour chaque fonction
(contraintes sur les variables en entrée et en sortie). Ces résumés vont être
réutilisés si possible afin d'éviter de ré-exécuter la fonction correspondante.
La génération automatique de ces résumés est présentée comme se faisant par
``analyse statique interprocédurale'' mais se rattacherait plutôt à une analyse
dynamique car utilisant une exécution symbolique (et résolution de contraintes).

\section{\textsc{Synergy}, \textsc{Dash} et \textsc{Yogi}}

\textsc{Synergy} \cite{SYNERGY} est un algorithme combinant du test (essayer
d'atteindre un état d'erreur) et une abstraction (trouver une abstraction
suffisamment précise montrant qu'aucun chemin ne peut atteindre un état
d'erreur). La sous-approximation du test et la sur-approximation de
l'abstraction sont raffinées de manière itérative. L'abstraction est utilisée
pour guider la génération de tests. Les tests sont utilisés pour décider
{\em où} raffiner l'abstraction.\\

Les états de l'abstraction, les régions, sont des classes d'équivalence des
états du programme concret. S'il n'existe aucun chemin de la région initiale
vers une région d'erreur, alors il n'existe aucune suite de transitions
concrètes menant d'un état initial concret à un état d'erreur concret.\\

\textsc{Dash} \cite{DASH} est une évolution de \textsc{Synergy}, prenant en
compte les appels de procédure et les pointeurs (contrairement à
\textsc{Synergy}). \textsc{Dash} raffine l'abstraction en utilisant uniquement
les relations d'alias mises en évidence par les tests. La génération de tests
guide non seulement {\em où} raffiner l'abstraction, mais aussi {\em comment}
la raffiner. Cet algorithme est implémenté dans l'outil \textsc{Yogi}
\cite{YOGI}.

\section{\textsc{Sage}}

Cet outil \cite{SAGE} utilise une analyse dynamique uniquement afin de générer
des tests pour des programmes au format binaire x86. Il combine une exécution
symbolique à du {\em fuzz testing}. Une première exécution avec des entrées
valides permet de récupérer une trace d'exécution du programme. L'exécution
symbolique de cette trace permet de collecter les contraintes du chemin
d'exécution. De nouveaux chemins sont générés par négation des contraintes,
à la manière de \textsc{PathCrawler} \cite{PathCrawler} et autres outils
similaires.

\section{\textsc{Smash}}

Cet outil \cite{SMASH} combine une abstraction par prédicats et une génération
dynamique de tests (par exécution concolique). Pour chaque fonction, un résumé
est calculé par analyse statique (vrai pour toutes les exécutions, permettant
de prouver l'absence d'erreurs, c'est une sur-approximation) et un autre résumé
est calculé par analyse dynamique (vrai pour quelques exécutions uniquement,
permettant de montrer l'existence d'erreurs, c'est une sous-approximation). Ces
résumés sont calculés à la demande et seront utilisés aussi bien par l'analyse
statique que par l'analyse dynamique (les deux analyses s'exécutent
simultanément).\\

Ces résumés sont progressivement raffinés pour chaque fonction, afin de prouver
qu'une propriété n'est jamais violée (si un résumé statique est applicable), ou
de mettre en évidence une exécution violant une propriété (si un résumé
dynamique est applicable). Par construction, il n'est pas
possible que les deux résumés soient applicables.\\


\begin{shaded}
Analyse compositionnelle : mémoization des résultats intermédiaires sous la
forme de résumés réutilisables.
\end{shaded}


\subsubsection{Résumé des outils Microsoft}


\textsc{Slam} \cite{SLAM} utilise une abstraction par prédicat et un raffinement
de partition (implémentation de l'algorithme \textsc{Cegar} \cite{CEGAR}) pour
effectuer une analyse statique compositionnelle mais n'effectue pas d'analyse
dynamique. \textsc{Smart} \cite{SMART} exécute une analyse dynamique
compositionnelle. C'est une extension de l'algorithme d'analyse dynamique non
compositionnelle de \textsc{Dart} \cite{DART}, mais n'effectue pas d'analyse
statique. \textsc{Synergy} \cite{SYNERGY} combine \textsc{Slam} \cite{SLAM} et
\textsc{Dart} \cite{DART} (\textsc{Cegar} compositionnel + test non
compositionnel). L'algorithme est intra-procédural. \textsc{Dash} \cite{DASH}
étend l'algorithme \textsc{Synergy}, il est inter-procédural mais non
compositionnel. \textsc{Smash} \cite{SMASH} est la version compositionelle de
\textsc{Dash}.



La figure~\ref{fig:microsoft-summary} résume graphiquement ces outils.



\begin{figure}
  \centering
  \begin{tabular}{|c|c|c|c|c|c|c|}
    \hline
    \multirow{3}{*}{Outils} & \multicolumn{3}{c|}{Analyse statique}
    & \multicolumn{3}{c|}{Analyse dynamique} \\
    & \multirow{2}{*}{intra-proc} & \multicolumn{2}{c|}{inter-proc}
    & \multirow{2}{*}{intra-proc} & \multicolumn{2}{c|}{inter-proc} \\
    & & non-compo & compo & & non-compo & compo \\
    \hline
    \textsc{Slam} \cite{SLAM} & & & $\surd$ & & & \\
    \hline
    \textsc{Dart} \cite{DART} & & & & & $\surd$ & \\
    \hline
    \textsc{Smart} \cite{SMART} & & & & & & $\surd$ \\
    \hline
    \textsc{Synergy} \cite{SYNERGY} & $\surd$ & & & $\surd$ & & \\
    \hline
    \textsc{Dash} \cite{DASH} & & $\surd$ & & & $\surd$ & \\
    \hline
    \textsc{Smash} \cite{SMASH} & & & $\surd$ & & & $\surd$ \\
    \hline
  \end{tabular}
  \caption{Résumé des outils de Microsoft}
  \label{fig:microsoft-summary}
\end{figure}





\section{Analyses statique et dynamique pour la génération d'invariants}

Cette méthode \cite{fromTestsToProofs} propose une solution au problème du
passage à l'échelle de la génération d'invariants (de programmes impératifs) par
résolution de contraintes. Les invariants arithmétiques linéaires sont générés
d'après les informations obtenues par interprétation abstraite du programme, par
exécution concrète et par exécution symbolique du programme. Ces informations
permettent de générer des contraintes qui vont permettre au solveur de
contraintes de simplifier le système de contraintes et de réduire l'espace de
recherche.

\section{\textsc{Cegar} : Raffinement d'abstraction guidé par des
  contre-exemples}

Le raffinement d'abstraction guidé par des contre-exemples \cite{CEGAR} associe
l’abstraction par prédicats et le model-checking : une abstraction du programme
est générée à partir d’un ensemble de prédicats et invariants. Si le
model-checking prouve la non-accessibilité des états d'erreurs de l'automate,
alors le modèle concret est correct (pas d'erreurs de sûreté ou de liveness).
Si le model-checking a trouvé un contre-exemple pour le modèle abstrait il faut
déterminer s'il correspond à un contre-exemple réel dans le système concret.
Pour cela, l'algorithme détermine s'il existe une trace d'exécution concrète
correspondant à la trace d'exécution abstraite aboutissant au contre-exemple.
Si une telle trace existe, un bug a été trouvé. Sinon, de nouveaux prédicats
seront créés pour raffiner l'abstraction afin que ce contre-exemple en soit
absent à la prochaine itération. Et ainsi de suite. Ce processus peut ne pas
terminer. Plusieurs outils de vérification se basent sur cette méthode, parmi
lesquels \textsc{Blast} \cite{BLAST}, \textsc{Magic} \cite{MAGIC} et
\textsc{Slam} \cite{SLAM}.\\

Cette approche élimine les contre-exemples un par un, l'abstraction ainsi
générée peut donc mettre un certain temps avant de converger vers une forme
acceptable. Une amélioration a été proposée afin d'accélérer la convergence du
raffinement de l'abstraction : \textsc{Cegaar} \cite{CEGAAR}. Cette technique
élimine une infinité de contre-exemples (traces infaisables) de la forme
$\alpha . \lambda^* . \beta$ en une seule étape, où $\lambda$ correspond à une
ou plusieurs exécutions d'une boucle.

\section{\textsc{DSD-Crasher} et \textsc{Check'n'Crash}}

L'outil \textsc{DSD-Crasher} \cite{DSD-Crasher} combine une première analyse
dynamique, une analyse statique et une seconde analyse dynamique. La première
analyse dynamique utilise une génération de tests et des techniques
d'apprentissage pour générer des invariants probables (inférence de la
spécification par \textsc{Daikon} \cite{discover-invariants}).\\

Les deux dernières étapes sont celles de l'outil \textsc{Check'n'Crash}
\cite{ChecknCrash}. L'analyse statique (résolution de contraintes par
\textsc{ESC/Java} \cite{ESC/Java}) va émettre des alarmes concernant le
non-respect des invariants, et la seconde analyse dynamique va tenter de
confirmer ces alarmes par une génération de tests (\textsc{JCrasher}
\cite{JCrasher}). La classification des alarmes et la génération de tests sont
très dépendantes de la qualité des invariants générés par \textsc{Daikon}.\\

Cette méthode se distingue de \textsc{Sante} \cite{SANTE} par son analyse
dynamique préliminaire qui détecte des invariants afin de guider l'analyse
statique. En revanche, elle n'utilise pas le {\em slicing} qui permet
d'augmenter le taux de classification des alarmes par l'analyse dynamique.
